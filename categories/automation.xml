<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Elizabeth Zagroba: Software Tester (Posts about automation)</title><link>https://elizabethzagroba.com/</link><description></description><atom:link href="https://elizabethzagroba.com/categories/automation.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>© 2022 &lt;a href="mailto:me@elizabethzagroba.com"&gt;Elizabeth Zagroba&lt;/a&gt; Mozilla Public License 2.0</copyright><lastBuildDate>Sun, 13 Feb 2022 18:49:27 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Unblocking Your Test Strategy</title><link>https://elizabethzagroba.com/posts/2021/unblocking_your_test_strategy/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;figure&gt;&lt;img src="https://elizabethzagroba.com/images/posts/2021/lightbulb.jpeg"&gt;&lt;/figure&gt; &lt;p&gt;In my new role as Quality Lead for my department, I get to figure out how to infuse everybody's work with "quality", and also figure out what that means exactly. &lt;/p&gt;
&lt;p&gt;One of my colleagues made it easy for me on my second day by coming with a relatively concrete problem: they wanted an acceptance environment for their team. Their team (henceforth: Eager Team) integrated with chronically overloaded and busy team (henceforth: Busy Team), so they wanted an environment where they could test their stuff together before it went into production. They wanted me to help set that up. &lt;/p&gt;
&lt;p&gt;I started my conversation with Eager Team Lead by taking one step back: why did they want this environment? They'd proposed a solution, but I wanted to spend at least a few minutes digging into the problem space with them to hear more about why they wanted this.&lt;/p&gt;
&lt;hr&gt;
&lt;h4&gt;Come up with dream scenario&lt;/h4&gt;
&lt;p&gt;I asked Eager Team Lead what their dream setup would be for their test automation, and why that was the dream.&lt;/p&gt;
&lt;p&gt;Eager Team and Busy Team already had a test environment hooked up to one another. But they both threw whatever they were in the middle of on that environment. Eager Team couldn't count on a stable, usable version of Busy Team's software, and vice versa. Eager Team wanted a place to see what would happen against the production version of Busy Team's code. They wanted to automate all the things they could, and have a place to run that automation. &lt;/p&gt;
&lt;h4&gt;Identify (and confirm they are indeed) constraints&lt;/h4&gt;
&lt;p&gt;Unfortunately Busy Team was busy. They wouldn't be able to make setting up an environment for Eager Team a priority in the next few months. I had that impression, and so did Eager Team Lead. They were, after all, Busy Team. But I wanted to make sure that the busyness of Busy Team was a constraint. I took on the action point to follow up with Boss Person about how we could both (1) check that Busy Team was indeed too busy, and (2) how to get this request on Busy Team's long list for the future.&lt;/p&gt;
&lt;p&gt;I also dispelled one of assumptions underlying Eager Team Lead's dream setup: it was important to test everything, in an automated way, in the ideal environment, or else testing wouldn't be valuable. I explained that it's &lt;a href="https://app.thestorygraph.com/books/8ba29269-1843-4ac1-be0c-226752b17937"&gt;impossible to test everything&lt;/a&gt;. Testing in an automated way would be more likely to reveal known unknowns than the unknown unknowns their team was interested in. And that it wasn't all-or-nothing - every little bit would help.&lt;/p&gt;
&lt;h4&gt;Choose achieveable pieces within constraints&lt;/h4&gt;
&lt;p&gt;Rather than killing the dream, I identified a valuable first step in the direction of the dream. Eager Team would write down, in English to start, 3-5 things that they want to test using both their software and Busy Team's. They'd show those to their product owner to make sure they were things customers cared about. From there, we could look at whether to build automation, and if so, where to run it. There was that test environment already. We had production, could we use feature flags? Could we keep the data only visible to our employees internally? &lt;/p&gt;
&lt;p&gt;I knew I'd hit a nerve when Eager Team Lead said "Oh, we can just start iterating over this!" Because of course, the software itself is not the only thing you can build in an iterative way. Your test automation can also mitigate risk, confirm assumptions, and provide value along the way. &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;So how'd it go? I confirmed Busy Team's busyness, and got more details on how and when to add this request to their list. I'm following up with Eager Team next week to see where they are in identifying valuable scenarios, or if I should jump in there too. &lt;/p&gt;
&lt;p&gt;But wow, what a feeling to be able to lift the weight of "I need a thing I don't know how to build and don't think I can ever get" off someone's shoulders and replace it with "I know what to do next and it's achievable." &lt;/p&gt;
&lt;p&gt;Stay tuned for more quality leading to come.&lt;/p&gt;</description><category>automation</category><category>coaching</category><category>risk-based-testing</category><category>testing</category><guid>https://elizabethzagroba.com/posts/2021/unblocking_your_test_strategy/</guid><pubDate>Thu, 21 Oct 2021 22:00:00 GMT</pubDate></item><item><title>Test Automation Day 2018</title><link>https://elizabethzagroba.com/posts/2020/2020-07-13_test_automation_day_2018/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;p&gt;I got a free ticket to Test Automation Day in 2018, just after I'd moved to Rotterdam. I was overwhelmed by the confluence of events: &lt;a href="https://twitter.com/techgirl1908"&gt;Angie Jones&lt;/a&gt; keynoting, &lt;a href="https://twitter.com/ard_kramer"&gt;Ard Kramer&lt;/a&gt; running the show, and meeting &lt;a href="https://twitter.com/amyjph"&gt;Amy Phillips&lt;/a&gt; in real life. (Neither of us were sure it was the first time we'd met because we'd been following each other on Twitter for so long!)&lt;/p&gt;
&lt;p&gt;My most shocking note from Angie's keynote is "clicker, no notes," because of course Angie had her talk down pat. In a talk that anticipated the current, urgent conversation in AI and machine learning, Angie recognized that we can't agree on what human ethics should look like. Figure out who you're advocating for, and tie the bugs back to that business value. You're not going to be able to define all the business requirements up front; expect the unexpected.&lt;/p&gt;
&lt;p&gt;Amy Phillips spoke about how tests in a DevOps environemnt allow you to get fast feedback. Like Agile, this style of working is not about minimizing the pain and struggle in developing software, but rather about bringing that pain forward. DevOps allows us to become aware of problems sooner, so we can act on them sooner. Running more tests is not necessarily better. Do not accept flaky tests. Free yourself from an overreliance on end-to-end tests and tests that cover non-critical paths to get your build time down. Rather than running tests on every commit, improve your monitoring. &lt;/p&gt;
&lt;p&gt;I've got some quotes from other talks and the panel that day: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;"A tester is someone who believes things can be different." ~ Jerry Weinberg&lt;/li&gt;
&lt;li&gt;"The team was not mature enough to determine priorities."&lt;/li&gt;
&lt;li&gt;"Maintain the relationships you want to build."&lt;/li&gt;
&lt;li&gt;"Are you just doing it because you can?" (regarding UI automation)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I can't tell everybody how welcome and in the right place I felt by being able to jump in this day on short notice. &lt;/p&gt;</description><category>automation</category><category>conference</category><category>testing</category><guid>https://elizabethzagroba.com/posts/2020/2020-07-13_test_automation_day_2018/</guid><pubDate>Sun, 12 Jul 2020 22:00:00 GMT</pubDate></item><item><title>This Too Shall Pass: Disposable Test Automation</title><link>https://elizabethzagroba.com/posts/2019/2019-03-29_this-too-shall-pass-disposable-test-automation/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;p name="00f1" id="00f1" class="graf graf--p graf-after--h3"&gt;A few different times, we wrote some Python code to help us test our products. And then we threw the code out.&lt;/p&gt;
&lt;p name="ad39" id="ad39" class="graf graf--p graf-after--p"&gt;We had the infrastructure in place to add tests to our continuous integration pipeline in Jenkins. It would have been as simple as merging the branch of our code into master. But it had served its purpose already.&lt;/p&gt;
&lt;h5 name="7e5f" id="7e5f" class="graf graf--h4 graf-after--p"&gt;Example 1: web feature integrating with desktop software&lt;/h5&gt;
&lt;p name="1da2" id="1da2" class="graf graf--p graf-after--h4"&gt;Our team owner a web-based product. It had lots of features, but the two we were concerned with for this were: it created an account and a project. These would be used in a desktop product built by different teams at our company. For this story, a flag would be set when you created a project in our product to allow for something new in the desktop software.&lt;/p&gt;
&lt;p name="9663" id="9663" class="graf graf--p graf-after--p"&gt;Our testing stack was built and maintained by our team alone. It was set up to look at the web UI and APIs, but not the desktop software. We had APIs to create projects and change this new project flag. We didn’t have an automated way to see exactly what would happen in the desktop software under these different circumstances.&lt;/p&gt;
&lt;p name="c2c2" id="c2c2" class="graf graf--p graf-after--p"&gt;We wrote tests to query the APIs to see that the settings we set were coming back as expected. Those went into the pipeline. We also wrote some Python code to create projects in each of the five different states. Then, we manually went into the desktop software, used each of the projects we created, and looked at what happened in the desktop software. The information we discovered was enough to determine that the work for our team and the work for the desktop software teams was complete.&lt;/p&gt;
&lt;p name="8f6c" id="8f6c" class="graf graf--p graf-after--p"&gt;We did not add these tests to the pipeline. The branch got removed from the project without getting merged into master once the story was completed.&lt;/p&gt;
&lt;h5 name="5b5e" id="5b5e" class="graf graf--h4 graf-after--p"&gt;Example 2: crude performance test&lt;/h5&gt;
&lt;p name="a60d" id="a60d" class="graf graf--p graf-after--h4"&gt;We wanted to simulate the load placed on our product by a different internal app. Unfortunately the owner of the internal app was unavailable in the short period of time we had to complete this task. To do this, we took existing feature tests we had running on our staging environments, parallelize them, and run them on a clone of our production environment.&lt;/p&gt;
&lt;p name="4cc3" id="4cc3" class="graf graf--p graf-after--p"&gt;Our production clone was available during the few days we were doing this test. It would not be available thereafter, considering the time and money we would have to invest in maintaining it. Our other staging environments had a different enough capacity that running a performance test there would not be meaningful. Our production environment would give us the information we needed once we released this build because the internal app ran there. We maintained a branch for a few days while we were writing and using the performance test, but without an environment to run it on, we threw it out.&lt;/p&gt;
&lt;h5 name="eea5" id="eea5" class="graf graf--h4 graf-after--p"&gt;Example 3: audit trail Excel export&lt;/h5&gt;
&lt;p name="fc7f" id="fc7f" class="graf graf--p graf-after--h4"&gt;We added an audit trail to our profile information for GDPR compliance. Our system could display the information in the UI and export it to Excel. We added tests to our pipeline for the UI bit. The exporting to Excel bit we didn’t. We wrote a test that ended by providing us a username and password. Manually, we’d login, go to the page with the Excel export, and confirm that the data in the file matched the changes the test had made.&lt;/p&gt;
&lt;p name="c098" id="c098" class="graf graf--p graf-after--p"&gt;The Excel exporter wasn’t a piece of code our team maintained. If this test failed, it would have likely been in that functionality, since we also had a UI test for the data integrity. We weren’t changing anything about the Excel export. The audit trail report was an important enough feature that we knew we’d smoke test it manually with every release, so we didn’t add this code to the repository.&lt;/p&gt;

&lt;p&gt;&lt;img alt="" src="https://elizabethzagroba.com/images/posts/2019/windows.png"&gt;&lt;/p&gt;
&lt;h5 name="a30f" id="a30f" class="graf graf--h4 graf-after--figure"&gt;What we asked ourselves when throwing out our automation&lt;/h5&gt;
&lt;ul class="postList"&gt;&lt;li name="a1f8" id="a1f8" class="graf graf--li graf-after--h4"&gt;What would we be asserting at the end of the test?&lt;/li&gt;&lt;li name="5de9" id="5de9" class="graf graf--li graf-after--li"&gt;If those asserts succeeded, would they give us false confidence that the feature was covered when we couldn’t account for the consequences?&lt;/li&gt;&lt;li name="f15d" id="f15d" class="graf graf--li graf-after--li"&gt;If these asserts failed, would that give us information about what to fix in our product?&lt;/li&gt;&lt;li name="90cc" id="90cc" class="graf graf--li graf-after--li"&gt;Would checking the code into the automation repository expose sensitive data about production?&lt;/li&gt;&lt;li name="2a56" id="2a56" class="graf graf--li graf-after--li graf--trailing"&gt;Would running these tests against our staging environments give us the information we needed?&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;
&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Originally published on &lt;a href="https://medium.com/@ezagroba/this-too-shall-pass-disposable-test-automation-6d0dadeff53"&gt;Medium&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;</description><category>automation</category><category>testing</category><guid>https://elizabethzagroba.com/posts/2019/2019-03-29_this-too-shall-pass-disposable-test-automation/</guid><pubDate>Thu, 28 Mar 2019 23:00:00 GMT</pubDate></item></channel></rss>