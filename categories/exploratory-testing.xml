<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Elizabeth Zagroba: Software Tester (Posts about exploratory-testing)</title><link>https://elizabethzagroba.com/</link><description></description><atom:link href="https://elizabethzagroba.com/categories/exploratory-testing.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>© 2020 &lt;a href="mailto:me@elizabethzagroba.com"&gt;Elizabeth Zagroba&lt;/a&gt; Mozilla Public License 2.0</copyright><lastBuildDate>Tue, 26 May 2020 18:40:50 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>If a test falls in a forest...</title><link>https://elizabethzagroba.com/posts/2020/2020-05-24_if_a_test_falls_in_a_forest/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;div&gt;&lt;p&gt;The saying goes "If a tree falls in a forest and no one is around to hear it, does it make a sound?" I have similar question that shapes the way I think about software testing: If a test is performed but no one takes action on the results, should I have performed it? I think not. &lt;/p&gt;
&lt;p&gt;If the answer to "Who cares?" is "No one," don't perform that test. If you're not going to take action on the results of your testing in the coming hours, days, or weeks, don't perform that test. The world around you will change in the meantime, and the old results will not be as valuable.&lt;/p&gt;
&lt;p&gt;One of the &lt;a href="https://www.agilealliance.org/agile101/12-principles-behind-the-agile-manifesto/"&gt;12 Agile Principles&lt;/a&gt; is simplicity, or maximizing the work not done. Testing on an agile team provides information to help decide what work should picked up in the coming iteration(s). But without meaningful collaboration or feedback, testing is a pile of work for no reason. Work is not meant to produce waste. Save your time and your sanity by thoughtfully analyzing what should not be done, and coming to an agreement with your team about it.&lt;/p&gt;
&lt;p&gt;My team gets scared about the quality of our product and skeptical about how I'm using my time when I describe what I'm not testing, or which automated tests I'm not going to run. "But isn't testing your job?" says the look on their faces. "But then what are you going to do?" is what they manage to say. Rather than capitulating for appearances, to just "look busy," I take this as a challenge to make my exploratory testing and other work I'm doing for the team more visible. &lt;/p&gt;
&lt;h4&gt;Risk-based testing&lt;/h4&gt;
&lt;p&gt;In her &lt;a href="https://www.ministryoftesting.com/dojo/series/testbash-home/lessons/reverse-engineer-your-way-to-adopting-a-risk-based-testing-approach-nishi-grover-garg"&gt;TestBash Home talk&lt;/a&gt;, &lt;a href="https://twitter.com/testwithnishi"&gt;Nishi Grover Garg&lt;/a&gt; asked us to think about estimating impact and likelihood (with possible home intruders as an example). I'd have trouble pinning down our no-estimates team on concrete numbers for undesireable software behavior. &lt;/p&gt;
&lt;p&gt;&lt;span class="img_container" style="display: inline-block;"&gt;&lt;img alt="" src="https://elizabethzagroba.com/images/posts/2020/nishi-impact-likelihood.png" style="display:block; margin-left: auto; margin-right: auto;" title="Slide from Nishi's TestBash Home talk"&gt;&lt;span class="img_caption" style="display: block; text-align: center;"&gt;Slide from Nishi's TestBash Home talk&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;But it does reflect the conversations &lt;a href="http://quality-intelligence.com/documents/DesignBehindthePlan.pdf"&gt;Fiona Charles's test strategy workshop&lt;/a&gt; encouraged me to spark on my team. We do talk about "Yes, this would be a problem, but customers can use this work-around." Or "Yes, we could dive in and investigate whether than could ever happen, but is that more important than picking up the next story?" Being able to identify risks and have thoughtful conversations about their threat to stakeholders allows us to make informed decisions about how we should be spending our time. In testing, we don't always want the most information, we want to discover the best information about the product as efficiently as we can. &lt;/p&gt;
&lt;h4&gt;Examples from my current project&lt;/h4&gt;
&lt;h5&gt;Cross-browser testing&lt;/h5&gt;
&lt;p&gt;We were preparing our web application for a big marketing presentation. The presenter had Firefox as the default browser on their PC. We had a script of the actions they'd perform on stage, and which pages the audience would see. I happened to find bugs on pages we weren't showing, or in the way the scroll bars behaved in Chrome rather than Firefox on my Mac. &lt;/p&gt;
&lt;p&gt;I did not add these issues as bugs in our tracking system, or dig into them further. I knew that they did not pose a risk for the presentation, and a new design would be coming along before customers would potentially use those pages in Chrome on a Mac.s &lt;/p&gt;
&lt;h5&gt;The pipeline&lt;/h5&gt;
&lt;p&gt;We have a pipeline. It runs the tests we've automated at the API and the browser levels against the build in our test environment. I hoped it would inspire the team to think about what the next step could be: getting the tests to run against before merging into our main line, setting up an environment where we're not dependent on the (shared) test environment, looking at the results to see where our application or tests need to change. &lt;/p&gt;
&lt;p&gt;But we don't look at the results. We don't have alerts, we don't open the page during standup, we don't use them as a reference when we're debugging, we don't have a habit of looking at the results. If we do happen to look at the results, we don't take action on it. Building the stability of our feedback loop is not seen as high-priority a task as building new features. &lt;/p&gt;
&lt;p&gt;We don't need to run this pipeline. It's using up AWS resources. Looking at the long line of red X's on the results page only provides alert fatigue. We would be better served by not running these tests. &lt;/p&gt;
&lt;h5&gt;Minimum viable deadline&lt;/h5&gt;
&lt;p&gt;We promised to deliver a feature to a dependent team by a sadline. (A sadline is a deadline without consequences.) In the week before the sadline, three stories were left. On the first story, I found a mistake the developer declared "superficial" when he was lamenting our lack of &lt;a href="https://katrinatester.blogspot.com/2016/12/the-testing-pendulum-finding-balance-in.html"&gt;deep testing&lt;/a&gt;. He decided to review the automated tests I'd written for the second story. He found a couple of use-cases that would require a very particular set of circumstances to occur. I wanted to encourage the behavior of reviewing the tests and thinking about what they're doing more deeply, so I spent the last hour and a half before a holiday weekend automating these two cases. &lt;/p&gt;
&lt;p&gt;I'd drafted some basic automated tests for the third story, but the last feature went relatively unexplored. I should have used my scant time to test the third story more thoroughly instead. The complicated tests for the second story could have waited until next week. While we would be curious about the results, it would not have stopped our delivery of the feature. I should not have written them. &lt;/p&gt;
&lt;p&gt;&lt;span class="img_container" style="display: inline-block;"&gt;&lt;img alt="" src="https://elizabethzagroba.com/images/posts/2020/far-side-tree-falling.jpg" style="display:block; margin-left: auto; margin-right: auto;" title="Far Side cartoon"&gt;&lt;span class="img_caption" style="display: block; text-align: center;"&gt;Far Side cartoon&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;You may be scared to say no to testing things that don't matter, where the performance will not reveal any risks or cause any follow-up actions to take place. It may be tempting to spend a bunch of time testing all the things you can think of, and only reporting on the tests that yield meaningful results. &lt;/p&gt;
&lt;p&gt;But life is not about keeping busy. Make your time at work meaningful by executing meaningful work and declining to do things that aren't important right now.&lt;/p&gt;&lt;/div&gt;</description><category>exploratory-testing</category><category>risk-based-testing</category><category>testbash</category><category>testing</category><guid>https://elizabethzagroba.com/posts/2020/2020-05-24_if_a_test_falls_in_a_forest/</guid><pubDate>Sat, 23 May 2020 22:00:00 GMT</pubDate></item><item><title>Exploratory Testing with the Chrome Network Tab</title><link>https://elizabethzagroba.com/posts/2019/2019-03-29_exploratory-testing-with-the-chrome-network-tab/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;div&gt;&lt;p name="6c32" id="6c32" class="graf graf--p graf-after--h3"&gt;I needed to the loading time of a login over a slow network. The internet connection I had was too fast to see all the visual behavior and the backend redirects happening during the process. I opened the Network tab in the Chrome developer tools and switched the throttling option to &lt;code class="markup--code markup--p-code"&gt;Slow 3G&lt;/code&gt;. (A yellow triangular yield symbol appeared next to the Network tab to remind me that I’d throttled my network.) Running over &lt;code class="markup--code markup--p-code"&gt;Slow 3G&lt;/code&gt; allowed me to see what someone trying access the site from a phone or tablet might experience.&lt;/p&gt;

&lt;p name="cd6d" id="cd6d" class="graf graf--p graf-after--p"&gt;&lt;em class="markup--em markup--p-em"&gt;The screenshots below are from the login on hackdesign.org, a program I highly recommend for getting up-to-speed on user experience design.&lt;/em&gt;&lt;/p&gt;

&lt;p name="29ea" id="29ea" class="graf graf--p graf-after--p"&gt;With the Network tab open, I could do a few things:&lt;/p&gt;

&lt;ol class="postList"&gt;&lt;li name="8374" id="8374" class="graf graf--li graf-after--p"&gt;I could see what API calls were being made. I looked at the bottom of the &lt;code class="markup--code markup--li-code"&gt;Name&lt;/code&gt; column to see how many calls there were overall, and sorted it to discover if we were retrieving things from the server that I expected to be cached. I clicked the &lt;code class="markup--code markup--li-code"&gt;Preserve log&lt;/code&gt; checkbox before I started so I could see what happened even after I went to another page.&lt;/li&gt;&lt;li name="ef06" id="ef06" class="graf graf--li graf-after--li"&gt;I could see which calls were redirects. The &lt;code class="markup--code markup--li-code"&gt;Status&lt;/code&gt;column had numbers in the 300 range for redirects. I love&lt;a href="https://httpstatuses.com/" data-href="https://httpstatuses.com/" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank"&gt; httpstatuses.com&lt;/a&gt; for what each one means more precisely. Redirects might indicate something could be optimized.&lt;/li&gt;&lt;li name="6d41" id="6d41" class="graf graf--li graf-after--li"&gt;I could tell how much time each of those network calls took. The &lt;code class="markup--code markup--li-code"&gt;Time&lt;/code&gt; column allowed me to sort by milliseconds to find the call that took the longest.&lt;/li&gt;&lt;/ol&gt;

&lt;p&gt;&lt;span class="img_container" style="display: inline-block;"&gt;&lt;img alt="" src="https://elizabethzagroba.com/images/posts/2019/chrome-network-tab.png" style="display:block; margin-left: auto; margin-right: auto;" title="What I used in the Network tab of the Chrome developer tools. HackDesign.org login only took 6 seconds."&gt;&lt;span class="img_caption" style="display: block; text-align: center;"&gt;What I used in the Network tab of the Chrome developer tools. HackDesign.org login only took 6 seconds.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p name="de62" id="de62" class="graf graf--p graf-after--figure"&gt;I discovered logging in and logging out took about 20 seconds on the test environment over Slow 3G. (This time appeared in the &lt;code class="markup--code markup--p-code"&gt;Load&lt;/code&gt; text in red at the bottom of the Network tab.) Was this too slow? To answer this question, I needed an oracle.&lt;/p&gt;

&lt;p name="7704" id="7704" class="graf graf--p graf-after--p"&gt;I decided to compare the behavior on the test environment to our production environment. On production, login took 60 seconds! When I sorted the network calls by &lt;code class="markup--code markup--p-code"&gt;Time&lt;/code&gt;, I could see that the bulk of loading time was spent retrieving messages to display on the logged-in page. Both 20 and 60 seconds for a login seemed unacceptably slow to me, so I took it to my team.&lt;/p&gt;

&lt;p name="d153" id="d153" class="graf graf--p graf-after--p"&gt;My team agreed that this behavior was bad. Unfortunately, we decided to prioritize users on fast networks over users on slow ones, and changing this behavior wasn’t a priority for our release.&lt;/p&gt;

&lt;p name="f224" id="f224" class="graf graf--p graf-after--p"&gt;When I sorted the network calls by &lt;code class="markup--code markup--p-code"&gt;Name&lt;/code&gt;, I found some unexpected URLs I did not expect to be involved during a login. I tested a bit more around the feature in different places, found a bug in the behavior, and asked around a few different teams before I got the bug reported to the correct team.&lt;/p&gt;

&lt;h5 name="d83e" id="d83e" class="graf graf--h4 graf-after--p"&gt;Moral of the story&lt;/h5&gt;

&lt;p name="715e" id="715e" class="graf graf--p graf-after--h4 graf--trailing"&gt;You have a powerful web performance testing tool at your disposal. Give it a try and see what you find.&lt;/p&gt;

&lt;p&gt;
&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Originally published on &lt;a href="https://medium.com/@ezagroba/exploratory-testing-with-the-chrome-network-tab-f093e1b3d725"&gt;Medium&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;</description><category>exploratory-testing</category><category>testing</category><guid>https://elizabethzagroba.com/posts/2019/2019-03-29_exploratory-testing-with-the-chrome-network-tab/</guid><pubDate>Thu, 28 Mar 2019 23:00:00 GMT</pubDate></item><item><title>Have I Tried Enough Weird Stuff?</title><link>https://elizabethzagroba.com/posts/2019/2019-01-25_have-i-tried-enough-weird-stuff/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;div&gt;&lt;p name="fd7f" id="fd7f" class="graf graf--p graf-after--h3"&gt;I was testing a piece of software that collected a person’s addresses for shipping within the United States. My developer had tried zip codes in the direct vicinity of our office in Manhattan, which all started with 1. I tried the zip codes for my hometown in New Jersey and the college I attended in Maine, both of which started with 0. Together we determined that the zip codes (and other address fields) needed to be stored differently so leading zeros would not be cut off. But it got me thinking: what other things might occur that were outside the direct experience of me and my developer?&lt;/p&gt;

&lt;p name="83bc" id="83bc" class="graf graf--p graf-after--p"&gt;So I asked the internet.&lt;/p&gt;

&lt;p name="cf4f" id="cf4f" class="graf graf--p graf-after--p"&gt;That’s when I first came across &lt;a href="https://www.mjt.me.uk/posts/falsehoods-programmers-believe-about-addresses/" data-href="https://www.mjt.me.uk/posts/falsehoods-programmers-believe-about-addresses/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"&gt;Falsehoods programmers believe about addresses&lt;/a&gt;. We were constrained to collecting American shipping addresses, so things like “are the odd street numbers all on the same side?” weren’t our concern. But plenty of them were. Was our form going to allow people whose shipping address was any of these?&lt;/p&gt;

&lt;ul class="postList"&gt;&lt;li name="a522" id="a522" class="graf graf--li graf-after--p"&gt;a post office box&lt;/li&gt;&lt;li name="cf1b" id="cf1b" class="graf graf--li graf-after--li"&gt;outside one of the fifty states (Washington D.C., Puerto Rico, Guam, etc.)&lt;/li&gt;&lt;li name="766c" id="766c" class="graf graf--li graf-after--li"&gt;on an American military base&lt;/li&gt;&lt;li name="dda7" id="dda7" class="graf graf--li graf-after--li"&gt;a fractional number&lt;/li&gt;&lt;/ul&gt;

&lt;p name="57b2" id="57b2" class="graf graf--p graf-after--li"&gt;As I tested inputs on other applications, I kept wondering if I was only thinking of things I already knew about, or if the problem space was bigger than I could conceive. I’ve come across a few lists that I love to review with my developers before they start building an input field (or an API parameter) so we can agree on what kind of validation we’re going to do.&lt;/p&gt;

&lt;p name="bdeb" id="bdeb" class="graf graf--p graf-after--p"&gt;&lt;a href="http://testobsessed.com/wp-content/uploads/2011/04/testheuristicscheatsheetv1.pdf" data-href="http://testobsessed.com/wp-content/uploads/2011/04/testheuristicscheatsheetv1.pdf" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"&gt;The Test Heuristics Cheat Sheet&lt;/a&gt; provides a great jumping-off point specific inputs for text fields on the first page and different ways to try inputting them on the second page.&lt;/p&gt;

&lt;p name="97d8" id="97d8" class="graf graf--p graf-after--p"&gt;&lt;a href="https://github.com/minimaxir/big-list-of-naughty-strings" data-href="https://github.com/minimaxir/big-list-of-naughty-strings" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"&gt;The Big List of Naughty Strings&lt;/a&gt; collects different kinds of characters (languages with non-Roman characters, emojis, Javascript that might trigger script injection, etc.) in one place so I don’t have to search for each of these cases individually. &lt;a href="https://github.com/minimaxir/big-list-of-naughty-strings/blob/master/blns.txt" data-href="https://github.com/minimaxir/big-list-of-naughty-strings/blob/master/blns.txt" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"&gt;I usually copy-paste the ones we’ve agreed we want to support from here&lt;/a&gt;. [Note: I recommend bookmarking this repository so you’re not accidentally getting NSFW results after searching “naughty strings.”]&lt;/p&gt;

&lt;p name="0d24" id="0d24" class="graf graf--p graf-after--p"&gt;Searching for “Falsehoods programmers believe about {input type}” is my go-to for more specific types of inputs. &lt;a href="https://github.com/kdeldycke/awesome-falsehood" data-href="https://github.com/kdeldycke/awesome-falsehood" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"&gt;There’s a list of a bunch of them&lt;/a&gt;, but these are some of my favorites:&lt;/p&gt;

&lt;ul class="postList"&gt;&lt;li name="20c5" id="20c5" class="graf graf--li graf-after--p"&gt;&lt;a href="http://falsehoodsabouttime.com" data-href="http://falsehoodsabouttime.com" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank"&gt;Time&lt;/a&gt;&lt;/li&gt;&lt;li name="f7e6" id="f7e6" class="graf graf--li graf-after--li"&gt;&lt;a href="https://www.kalzumeus.com/2010/06/17/falsehoods-programmers-believe-about-names/" data-href="https://www.kalzumeus.com/2010/06/17/falsehoods-programmers-believe-about-names/" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank"&gt;Names&lt;/a&gt;&lt;/li&gt;&lt;li name="b82f" id="b82f" class="graf graf--li graf-after--li"&gt;&lt;a href="https://wiesmann.codiferes.net/wordpress/?p=15187" data-href="https://wiesmann.codiferes.net/wordpress/?p=15187" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank"&gt;Geography&lt;/a&gt;&lt;/li&gt;&lt;li name="aed1" id="aed1" class="graf graf--li graf-after--li"&gt;&lt;a href="https://haacked.com/archive/2007/08/21/i-knew-how-to-validate-an-email-address-until-i.aspx/" data-href="https://haacked.com/archive/2007/08/21/i-knew-how-to-validate-an-email-address-until-i.aspx/" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank"&gt;Emails&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;

&lt;p name="8e3e" id="8e3e" class="graf graf--p graf-after--li"&gt;I encourage you to keep asking “have I tried enough weird stuff?” and deciding together with your developers what constitutes “weird.”&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://elizabethzagroba.com/images/posts/2019/arrows.jpeg"&gt;&lt;/p&gt;
&lt;section name="7d8d" class="section section--body section--last"&gt;&lt;div class="section-divider"&gt;&lt;hr class="section-divider"&gt;&lt;/div&gt;&lt;div class="section-content"&gt;&lt;div class="section-inner sectionLayout--insetColumn"&gt;&lt;p name="1dd4" id="1dd4" class="graf graf--p graf--leading graf--trailing"&gt;&lt;em class="markup--em markup--p-em"&gt;Thanks to Trish Khoo and Anne-Marie Charrett for the impetus to publish this, and Joep Schuurkes for pointing out that my headline falls under &lt;/em&gt;&lt;a href="https://en.wikipedia.org/wiki/Betteridge%27s_law_of_headlines" data-href="https://en.wikipedia.org/wiki/Betteridge%27s_law_of_headlines" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"&gt;&lt;em class="markup--em markup--p-em"&gt;Betteridge’s law&lt;/em&gt;&lt;/a&gt;&lt;em class="markup--em markup--p-em"&gt;.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/section&gt;



&lt;p&gt;&lt;em&gt;Originally published on &lt;a href="https://medium.com/@ezagroba/have-i-tried-enough-weird-stuff-7ed4105ae994"&gt;Medium&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;</description><category>exploratory-testing</category><category>testing</category><guid>https://elizabethzagroba.com/posts/2019/2019-01-25_have-i-tried-enough-weird-stuff/</guid><pubDate>Thu, 24 Jan 2019 23:00:00 GMT</pubDate></item></channel></rss>