<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Elizabeth Zagroba: Organizational Anarchist (Posts about code-review)</title><link>https://elizabethzagroba.com/</link><description></description><atom:link href="https://elizabethzagroba.com/categories/code-review.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Â© 2022 &lt;a href="mailto:me@elizabethzagroba.com"&gt;Elizabeth Zagroba&lt;/a&gt; Mozilla Public License 2.0</copyright><lastBuildDate>Sun, 28 Aug 2022 14:47:48 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>From Crafting Project to Critical Infrastructure</title><link>https://elizabethzagroba.com/posts/2022/06_12_from_crafting_project_to_critical_infrastructure/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;figure&gt;&lt;img src="https://elizabethzagroba.com/images/posts/2022/megaphone.jpg"&gt;&lt;/figure&gt; &lt;h3&gt;Just for me&lt;/h3&gt;
&lt;p&gt;Three years ago, I had a shit laptop. My company makes a Windows desktop software product that allows you to build your own applications. Mac users working the software could open it on their Windows virtual machine in Parallels. When I did that, my company's software crashed, Parallels crashed, and then my whole Mac crashed. My job was to create app builds, run them, and test them. Due to my shit laptop, I couldn't do that locally. &lt;/p&gt;
&lt;p&gt;Luckily, our app was also hosted in our public cloud. Through the cloud UI, you could make a build, see which build was on which of your environments, and deploying a new build. But the UI was...not an ideal workflow for me. It was slow to load, required several steps of clicking and waiting for a minute or two - just long enough to get distracted thinking about something else. A deploy process that might optimally take ~8 minutes took ~15 minutes as my mind wandered and the UI didn't update immediately. &lt;/p&gt;
&lt;p&gt;I needed a one-step process to deploy, with updates frequent enough to hold my attention. I decided to abandon the UI for the API. &lt;/p&gt;
&lt;p&gt;I wrote a Python script that took command-line input and printed output to the console as the steps of the process progressed. I used my two crafting days that month to break down the problem, setup the whole repository, and get the code to a state where it built and deployed an app to an environment. &lt;/p&gt;
&lt;p&gt;A code review from Joep Schuurkes moved the code from a long list of functions to different classes corresponding to the API endpoints I was calling. I think the commands were limited to &lt;code&gt;--build&lt;/code&gt; and &lt;code&gt;--deploy&lt;/code&gt;. To make sure the refactor was successful, I'd scroll up in my Terminal history and run those two commands again. Crafting days on subsequent months brought a bit more error-handling to account for mistypes on my side or failures/timeouts from the APIs. &lt;/p&gt;
&lt;p&gt;At this point, it was a solid tool that saved me about a half-hour per day. I presented it to the developers on my team, offering them access to the repository so they too could benefit from this time-savings. &lt;/p&gt;
&lt;p&gt;They were deeply unimpressed. They didn't have shit laptops, they had Windows laptops, they didn't have to run Parallels, they weren't constantly switching between branches and needing actual builds of the application to test. To them, this script was relatively useless. That was fine by me! The time and frustration the script saved me was more than worth the effort to build it. I used it several times a day myself, and got to use it as an example in the "Whole Team Approach to Continuous Delivery" workshop I paired with Lisa Crispin on. That was more than enough. &lt;/p&gt;
&lt;p&gt;&lt;span class="img_container" style="display: inline-block;"&gt;&lt;img alt="" src="https://elizabethzagroba.com/images/posts/2022/cloud-deployment-script.png" style="display:block; margin-left: auto; margin-right: auto;" title="Slide from the workshop"&gt;&lt;span class="img_caption" style="display: block; text-align: center;"&gt;Slide from the workshop&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;Pipelines emerge&lt;/h3&gt;
&lt;p&gt;Six months later, a developer on my team got excited to set up a pipeline for our application. They wanted to run static code analysis on a build of our application, and run our functional tests against a deployed application running in a deployed environment. They copy + pasted my code as a starting point for the build and deploy, copy + pasted the static code analysis scans from another unit, and connected the two in a pipeline that provided value to the wider team. Developers weren't great at running tests on their feature branches on their machines; now we had a pipeline that would do it for them. &lt;/p&gt;
&lt;p&gt;Other teams saw our pipeline and discovered my deployment script in the process. Rather than copy + pasting the code as my teammate did, they pinned their pipelines to the most recent version of the code on the master branch. &lt;/p&gt;
&lt;p&gt;With more users and use cases, fellow colleagues were eager to also use their two crafting days per month to add the features they needed. I'd receive pull requests of things I didn't need for a context I didn't have, or feature requests I used my limited crafting time to fulfill. Without a style guide, a linter, tests, or a set scope, it was hard to turn away pull requests weeks or months in the making that people were eager to see included in the master branch. I merged it to keep everyone unblocked. As the code grew to serve every individual need, I lost  interest in supporting what had originally been my darling pet project. &lt;/p&gt;
&lt;h3&gt;Still Valuable?&lt;/h3&gt;
&lt;p&gt;Two years after the original two-day crafting project, my role shifted from serving one team and one application to thinking about quality for the seven engineering teams in my unit. No longer did I need to deploy the application to a hosted environment. At the same time, my old team shifted where the repository was located, and the APIs I'd been calling in my script wouldn't do a lot of what they used to. &lt;/p&gt;
&lt;p&gt;I got to explore what it meant to be the Quality Lead for my unit, and nobody I served needed this script. I left the list of improvements I'd brainstormed for it languishing at the bottom of my personal Trello board. I didn't get any requests from other departments to use or update it. &lt;/p&gt;
&lt;h3&gt;Still Valuable!&lt;/h3&gt;
&lt;p&gt;Nine months later, the spark got reignited! A fork of the deployment script got presented in another unit, complete with a UI on top of it. Someone on my old project discovered my script, and decided to add a feature to upload builds from the new repository location to make it useful again. They shared the code for a review after just a few hours of effort. &lt;/p&gt;
&lt;p&gt;I had a chance to think through what parts of the repository were resuable for this use-case, which parts would be better copy + pasted for better readability, and got the merge request to a place where it fit in with the existing code style before anyone's heart and soul had been poured into it. &lt;/p&gt;
&lt;p&gt;Now a bloated script eight different actions, I decided to start writing tests for it. I didn't need the tests to make sure the existing code worked; everyone using it in their pipelines was enough to prove that. Tests will allow for future refactoring of the code and updating the version of the API I'm calling.&lt;/p&gt;
&lt;p&gt;The first test I added confirmed that the new functionality did what the code submitter expected it to do, gave me a way to change individual parameters  faster. and gave me the confidence and excitement I'd been missing. &lt;/p&gt;
&lt;p&gt;I'm just getting going on tests for the rest of the existing code, but I'm looking forward to it!&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Why do I tell you this story? Well, here's what I think when I look back at the evolution of this code base: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;write tests, even before you &lt;em&gt;really&lt;/em&gt; need them&lt;/li&gt;
&lt;li&gt;set up a linter and coding guidelines before you give anyone else access to your repo&lt;/li&gt;
&lt;li&gt;if you want to be precious about your code, tell people to fork instead of submitting merge requests&lt;/li&gt;
&lt;li&gt;if you want the code to be in its most findable place and shareable state, you'll have to invest the time to collaborate with people on their changes&lt;/li&gt;
&lt;li&gt;good things come to those who wait :)&lt;/li&gt;
&lt;/ul&gt;</description><category>apis</category><category>automation</category><category>code-review</category><category>python</category><category>testing</category><guid>https://elizabethzagroba.com/posts/2022/06_12_from_crafting_project_to_critical_infrastructure/</guid><pubDate>Fri, 17 Jun 2022 22:00:00 GMT</pubDate></item><item><title>Strengthen Your Code Review Skills</title><link>https://elizabethzagroba.com/posts/2022/02_27_strengthen_your_code_review_skills/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;p&gt;I spent my first two years at my current company getting my code reviewed and the following almost two years reviewing 3-10 merge requests per week. Our tech stack was in Python, with pytest as our test running, the requests library for API tests, and Selenium for browser tests, all hosted in our company's paid gitlab instance. All that experience shaped how (and whether I) offer feedback on the merge requests I reviewed for members of my own team and neighboring teams working in the same tech stack.&lt;/p&gt;
&lt;h3&gt;Define the relationship.&lt;/h3&gt;
&lt;p&gt;There are power dynamics at play in any relationship at work. For members of my team, they had to have a really good argument to refute one of my "suggestions" because I was their test specialist &lt;em&gt;and&lt;/em&gt; their team lead evaluating their ability to respond to feedback and change their behavior by performance review time. No pressure!&lt;/p&gt;
&lt;p&gt;For members of other teams, they had more power to push back. It could empower them with the knowledge I shared, but they were free to reject it. &lt;/p&gt;
&lt;h3&gt;Focus on what matters.&lt;/h3&gt;
&lt;p&gt;When I review a merge request, I start with the question "what is this code supposed to do?" If it's a merge request for my team, the JIRA ticket number in the title or the branch name would clue me in. For code from other teams, champions would use the description field to explain what the product change was and how the test code supported that. Most merge requests left me guessing a bit. I'd have to read the code contained in the tests to figure out what the test, and ultimately the product, was supposed to do.&lt;/p&gt;
&lt;p&gt;Reading the code also got me thinking about the things I was best equipped to help the code submitter with: maintainability and "what if?" scenarios. As a tester, I could look at a list of tests that create, read, and delete a thing and ask "is update also part of the picture here?" As a code reviewer with a longer tenure at the company, I had a more informed view of whether copy and pasting would work or if a new function was needed.&lt;/p&gt;
&lt;p&gt;We had two linters set up to run on every commit: flake8 covered style enforcement (indentation, blank lines, etc.) and vulture identified unused code. For issues of style that a machine couldn't decide, we had written guidelines to point to. I pointed to these three the most often:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;comments explain why the code is the way it is, not what it does (so code is clearer to read and update)&lt;/li&gt;
&lt;li&gt;setup and teardown should take place outside the test (so pytest reporting tells you there's an &lt;code&gt;error&lt;/code&gt; instead of a &lt;code&gt;failure&lt;/code&gt; when something's off)&lt;/li&gt;
&lt;li&gt;API tests assert the status code before any details about the response body (because the body's not going to have the right stuff in it anyway if the status code is wrong)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I would give feedback about these topics, trying to ask questions to disambiguate my observations from interpretations. I knew that the person who'd written the code had spent more time and thought steeped in the problem than I had. Questions allowed me to assume competence while gathering evidence to the contrary. &lt;/p&gt;
&lt;p&gt;As I read other people's code, I saw lots of weird stuff: stuff I would name differently, stuff I would put in a different order, stuff that took up more or fewer lines than I would have to write the same thing. My experience living in a non-native English speaking culture served me well here: I let it go. Was the test name meaningful to them and their team? Did putting it across a couple more lines help them understand it better? Was it actually a problem with what the code did or just a personal opinion? Did they want to set the constant right before they used it instead of at the top? Go for it! It works, I can understand what they meant, and that should be the threshold. My review was not an opportunity for me to show off my Python skills. I was there to help the code submitter with their tests. I reserved the right to remain silent on unimportant matters. &lt;/p&gt;
&lt;h3&gt;Communicate well.&lt;/h3&gt;
&lt;h4&gt;Praise the good!&lt;/h4&gt;
&lt;p&gt;Notice when people have done something well and praise them for it! Positive reinforcement is the best way to turn up the good on what's already happening in your code base.&lt;/p&gt;
&lt;h4&gt;Right level of abstraction&lt;/h4&gt;
&lt;p&gt;I reviewed merge requests that were 30% done that I mistook for 100% done; conversely I saw at 110% done that I would have killed at 30%. A little [WIP] label in the name of the merge request or bullet list of which tests were still missing helped me offer the code submitter the right kind of feedback at the right time. &lt;/p&gt;
&lt;p&gt;Sometimes, the code isn't the problem, the product is. I've seen a 500 http status code returned for something the user screwed up, which should be in the 400-range. A code comment "Should this be a 400 response?" opened up a more interesting conversation about where the product was in its lifecycle and the code submitter could lobby their team to change the product's behavior.&lt;/p&gt;
&lt;p&gt;If having the conversation about the code isn't the right approach, I tried having &lt;a href="https://elizabethzagroba.com/posts/2021/delivering_information_vs_delivering_meta_information/"&gt;the meta-conversation&lt;/a&gt; instead. "I'm not convinced this API spec is done. Where are you in that process?"&lt;/p&gt;
&lt;p&gt;&lt;span class="img_container" style="display: inline-block;"&gt;&lt;img alt="" src="https://elizabethzagroba.com/images/posts/2022/wtf.png" style="display:block; margin-left: auto; margin-right: auto;" title="Code quality measurement: WTFs/minute"&gt;&lt;span class="img_caption" style="display: block; text-align: center;"&gt;Code quality measurement: WTFs/minute&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h4&gt;Right format&lt;/h4&gt;
&lt;p&gt;Tone is hard in writing. I do prefer writing, because it gives me the opportunity to have several drafts, separating my WTFs-per-minute from what the code submitter receives. I just don't always hit send. Before leaving a comment on a particular line in gitlab, I ask myself: is this the right format? Have I removed any judgy adverbs like "just", "obviously", or "actually"? Would a video call, a Slack message, or a comment on the whole merge request be more likely to be embraced?&lt;/p&gt;
&lt;h4&gt;The receiving&lt;/h4&gt;
&lt;p&gt;One of the many tough things about feedback is that the receiver determines the priority of the feedback. (For all the other tough things about feedback, read &lt;a href="https://app.thestorygraph.com/books/15270135-7360-4e66-b079-4cbd618dfb76"&gt;&lt;em&gt;What Did You Say? The Art of Giving and Receiving Feedback&lt;/em&gt;&lt;/a&gt;.) The code submitter often completely miss what I meant the first time. Even if I thought I'd delivered my feedback as well as I could have, it wasn't always accepted. Everyone extracts different information from the same situation. The feedback that provides the most information can be the hardest to accept.&lt;/p&gt;
&lt;h3&gt;It doesn't have to be like this.&lt;/h3&gt;
&lt;h4&gt;Asynchronous&lt;/h4&gt;
&lt;p&gt;You may have read my first paragraph and asked yourself "why is she doing so many async code reviews?" and you'd be right! The company was scaling at a speed that I was forced to optimize for "number of minutes per day without video calls" over shared understanding.&lt;/p&gt;
&lt;h4&gt;Synchronous&lt;/h4&gt;
&lt;p&gt;Did you know that working in a pair or an ensemble can do all this feedback and knowledge-sharing stuff in a better way? See more about how an ensemble made learning happen in &lt;a href="https://ezagroba.github.io/mob-testing/"&gt;this slide deck&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;When I was able to, having a conversation helped me make sure that I was giving the right feedback at the right time to the right person. Pairing with the code submitter got not only the mistakes fixed, but also the thought processes behind those mistakes.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://elizabethzagroba.com/images/posts/2022/two_birds.jpg"&gt;&lt;/p&gt;
&lt;h3&gt;Don't take my word for it.&lt;/h3&gt;
&lt;p&gt;I have the benefit of learning from smart people who are also thinking through what code reviews are and what they can be. I have yet to be free at a time when &lt;a href="https://github.com/neontribe/code-reading-club/"&gt;the code reading club&lt;/a&gt; Felienne Hermans started has met, but I look forward to joining sometime in the future. Here is a collection resources that I've already found useful:&lt;/p&gt;
&lt;h4&gt;Videos&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Sarah Mei on &lt;a href="https://www.youtube.com/watch?v=YL-6RCTywbc"&gt;The Power of Agile&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Nina Zakharenko on &lt;a href="https://www.youtube.com/watch?v=6L3ZVLtSeo8"&gt;Code Review Skills for Pythonistas&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Sasha Laundy on &lt;a href="https://www.youtube.com/watch?v=hY14Er6JX2s"&gt;Giving and Getting Technical Help&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Books&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://app.thestorygraph.com/books/15270135-7360-4e66-b079-4cbd618dfb76"&gt;&lt;em&gt;What Did You Say? The Art of Giving and Receiving Feedback&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://app.thestorygraph.com/books/b15fe452-5b8e-49f5-9e0b-90da490b944c"&gt;&lt;em&gt;Crucial Conversations: Tool for Talking When Stakes Are High&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Blog posts&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Michaela Greiler on &lt;a href="https://www.michaelagreiler.com/respectful-constructive-code-review-feedback/"&gt;giving respectful code reviews&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Michaela Greiler on &lt;a href="https://www.michaelagreiler.com/accept-code-review-feedback/"&gt;how to handle criticism during code reviews&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Jessica Joy Kerr on &lt;a href="https://jessitron.com/2021/03/27/those-pesky-pull-request-reviews/"&gt;those pesky code reviews&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Angie Jones with &lt;a href="https://angiejones.tech/ten-commandments-code-reviews/"&gt;the 10 commandments of navigating code reviews&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Lucas Rocha on &lt;a href="https://lucasr.org/2011/01/29/micro-commits/"&gt;microcommits&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Quotes found on Twitter&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;April Wensel on &lt;a href="https://twitter.com/maaretp/status/1024995595973525510"&gt;compassionate code review&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Patricia Aas on the &lt;a href="https://twitter.com/pati_gallardo/status/1373343835330383878"&gt;zero-trust process&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Michaela Greiler on how &lt;a href="https://twitter.com/mgreiler/status/1482247806798733317"&gt;everybody needs an editor&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Michaela Greiler &lt;a href="https://twitter.com/mgreiler/status/1481902327640608770"&gt;thread on the biggest annoyances during code reviews&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Amy Edmondson on &lt;a href="https://twitter.com/AmyCEdmondson/status/1476198824012136460"&gt;psychological safety&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Jerry Weinberg on &lt;a href="https://twitter.com/mstine/status/1481660769456513029"&gt;egoless programming&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Allen Holub on &lt;a href="https://twitter.com/allenholub/status/1491168642586710016"&gt;async code reviews&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Allen Holub on &lt;a href="https://twitter.com/allenholub/status/1482564778149175298"&gt;inspecting quality in&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;Photo by &lt;a href="https://unsplash.com/@robinmathlener?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText"&gt;Robin Mathlener&lt;/a&gt; on &lt;a href="https://unsplash.com/?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText"&gt;Unsplash&lt;/a&gt;&lt;/p&gt;</description><category>code-review</category><category>communication</category><category>feedback</category><guid>https://elizabethzagroba.com/posts/2022/02_27_strengthen_your_code_review_skills/</guid><pubDate>Sat, 26 Feb 2022 23:00:00 GMT</pubDate></item></channel></rss>