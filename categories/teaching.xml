<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Elizabeth Zagroba: Software Tester (Posts about teaching)</title><link>https://elizabethzagroba.com/</link><description></description><atom:link href="https://elizabethzagroba.com/categories/teaching.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Â© 2021 &lt;a href="mailto:me@elizabethzagroba.com"&gt;Elizabeth Zagroba&lt;/a&gt; Mozilla Public License 2.0</copyright><lastBuildDate>Sun, 08 Aug 2021 10:18:34 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Give Them the Fish, Then Teach Them to Fish</title><link>https://elizabethzagroba.com/posts/2021/give_them_the_fish_then_teach_them_to_fish/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;div&gt;&lt;p&gt;A colleague came to me with a request the other day. I didn't handle it quite how I wanted to. The request went something like this:&lt;/p&gt;
&lt;p&gt;"I remember you were on the team for Big Scary product a couple years ago. Do you know if I can delete this List of Stuff from Big Scary product, and if I can automate that?"&lt;/p&gt;
&lt;p&gt;I did not know. It was two years ago. Big Scary product had gotten Bigger and Scarier in the meantime. &lt;/p&gt;
&lt;p&gt;But I knew where my team linked to our API specs from our customer-facing documentation. I applied the same principle to discover where Big Scary product API specs were. I looked at those specs and found the List of Stuff in a response body for an API call, but noticed that my colleague wouldn't have the ID the request required. So I looked at the API specs from a Bigger Scarier product. Combining a call from there would get the ID Big Scary product needed.&lt;/p&gt;
&lt;p&gt;I was short on time, so I answered the question directly. I said it was possible, and possible to automate, and provided the links to the specs for both products. My colleague thanked me, and left the conversation able to solve their problem quickly. &lt;/p&gt;
&lt;p&gt;I gave them the fish. What they learned from that interaction was: Elizabeth knows where to find stuff. I can come to her when I don't know how to find stuff and she will find it for me. That was the wrong lesson. &lt;/p&gt;
&lt;h3&gt;Give Them the Fish, Then Teach Them to Fish&lt;/h3&gt;
&lt;p&gt;A better lesson would have been: I know where to look for things. Elizabeth will give me the tools to know where to look, and empower me to do so. Now that I've got the access and seen it done once before, I can take a few more steps before I reach out Elizabeth the next time.&lt;/p&gt;
&lt;p&gt;Here's what I could have done to get to get this colleague there:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Explain where all the API specs live: I could have explained my thought process for finding the API specs, showed how I navigate using the headers and &lt;code&gt;Ctrl + F&lt;/code&gt; on the page, and compare the requests and responses to what's needed.&lt;/li&gt;
&lt;li&gt;Update them about who's on the team for Big Scary product now: I could have listed a few team members names who I knew were working on Big Scary product, or pointed my colleague to the Slack channel for the whole team.&lt;/li&gt;
&lt;li&gt;Introduce colleague to a member of the team for Big Scary product: Since this colleague was a tester, I could have started a direct message with them and the tester on the team for Big Scary product, copying the question from the DM I first received. &lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;What If I Only Teach Them to Fish?&lt;/h3&gt;
&lt;p&gt;What would have happened if I'd skipped what I'd done, and withheld the links to the API specs? &lt;/p&gt;
&lt;p&gt;I wouldn't have been able to guarantee that my colleague was in the learning zone. From what I knew about their situation, they were accumulating a lot of data that they wanted to delete. I didn't know what other pressures were coming from the team, but the need to automate it suggested it was a bigger problem than just a few extra entries in a database. &lt;/p&gt;
&lt;p&gt;Giving my colleague the fish, and &lt;em&gt;then&lt;/em&gt; teaching them to fish, relieves any of that pressure to deliver, and helps open them up to learning and growing. &lt;/p&gt;
&lt;h3&gt;Tell Them What You're Doing&lt;/h3&gt;
&lt;p&gt;Some colleagues are distracted, or dense, or not able to take away &lt;a href="https://elizabethzagroba.com/posts/2021/delivering_information_vs_delivering_meta_information/"&gt;meta-information&lt;/a&gt; from a conversation along with the information. They may stop listening after they have the answer. &lt;/p&gt;
&lt;p&gt;Combat this by sharing your motives. Remind them that you too are busy. Explain that your goal is to empower them. Encourage them to reach out to the team working on Big Scary product, so that those team members can also get good at knowing where to look and answering colleagues' questions. Tell them you're happy to help them again, but you'll expect more details of what they tried first. Then hold them to that. &lt;/p&gt;
&lt;p&gt;The best lesson is: I want to take a few more steps next time I have a problem, because I know I can, and Elizabeth expects more from me. &lt;/p&gt;&lt;/div&gt;</description><category>critical-thinking</category><category>leadership</category><category>mindset</category><category>teaching</category><category>testing</category><guid>https://elizabethzagroba.com/posts/2021/give_them_the_fish_then_teach_them_to_fish/</guid><pubDate>Sat, 07 Aug 2021 22:00:00 GMT</pubDate></item><item><title>The Long Haul</title><link>https://elizabethzagroba.com/posts/2021/the_long_haul/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;div&gt;&lt;p&gt;I've been both the lead of my team and a tester on that team for a year now. Getting answers, adapting to change, and identifying solutions have completely different time horizons in each of these roles. &lt;/p&gt;
&lt;hr&gt;
&lt;h4&gt;Tester experiments&lt;/h4&gt;
&lt;p&gt;Testing experiments can run quickly. A testing experiment might look like this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Call an API&lt;/li&gt;
&lt;li&gt;Inspect the output&lt;/li&gt;
&lt;li&gt;Compare that to the specification&lt;/li&gt;
&lt;li&gt;Question whether either or both need changing&lt;/li&gt;
&lt;li&gt;Talk to a developer about the changes&lt;/li&gt;
&lt;li&gt;Update the specification and/or tests&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;All of that happens within minutes or hours, or days if schedules are extremely incompatible and asynchronous communication is failing. I can be confident in the experiment's outcome. I can weigh the relative merits of caring vs. not caring about a particular error response code or required field, and leave my work at work. The next time I see a particular error response, I know what to look for and where changes might be needed. A failing test is evidence that something used to work in a particular way. &lt;/p&gt;
&lt;h4&gt;Team lead experiments&lt;/h4&gt;
&lt;p&gt;Team lead experiments take longer. A team lead experiment might look something more like this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Team members complain that it's hard to get their ideas in during refinement.&lt;/li&gt;
&lt;li&gt;I mention this to the talking-dominant team member at a 1-on-1.&lt;/li&gt;
&lt;li&gt;Talking-dominant team member dominates following refinement.&lt;/li&gt;
&lt;li&gt;I remind talking-dominant team member in Slack about our previous conversation.&lt;/li&gt;
&lt;li&gt;Talking-dominant team member spills over their allotted time during big unit meeting.&lt;/li&gt;
&lt;li&gt;I bring both of these instances in our 1-on-1, sharing the consequences (they're the single point of failure, other team members aren't heard) of their actions.&lt;/li&gt;
&lt;li&gt;Talking-dominant team member does it again.&lt;/li&gt;
&lt;li&gt;I ask team member what I can do to help them change their behavior, given that we are both adults in control of our own behavior. They agree that change is their responsibility. We agree that setting their microphone on mute at the start of the meeting would help.&lt;/li&gt;
&lt;li&gt;Talking-dominant team member dominates some of the following refinement, until I remind them to mute, after which other team members have time to think and contribute too.&lt;/li&gt;
&lt;li&gt;I ask talking-dominant team member to set up a Slackbot to send them a reminder to mute their microphone each week before the meeting.&lt;/li&gt;
&lt;li&gt;Other people are able to contribute at the following refinement. &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This took place over months. We're not to a point where we have a solution that works every time. I went in with a different hypothesis each time, not knowing when I'd hit on the right one:&lt;/p&gt;
&lt;p&gt;2. I think the talking-dominant team member isn't aware of their behavior.&lt;br&gt;
4. I think the team member has forgotten our first conversation.&lt;br&gt;
6. I think the team member doesn't understand the impact of their behavior.&lt;br&gt;
8. I think the team member hasn't found a tool or a trigger to change their habit.&lt;br&gt;
10. I think the team member needs both a tool and a trigger to change their habit.&lt;/p&gt;
&lt;p&gt;Any of the first four experiments taken by itself looks like a failure. The talking-dominant team member prevents other team members from contributing effectively. It takes me time as a leader to come up with a different hypothesis, try something else, and discover where to go from there. And this was a relatively straightforward issue to assess. Imagine how long it might take to find an effective response to a problem with more variables and more consequences.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;I'm also thinking not just about the experiments themselves, but how they might come across to the wider team. For the testing experiment, I could present my results in standup the next day as "I tested it, everything's good" but it's more valuable for everyone if I &lt;a href="https://www.ministryoftesting.com/dojo/lessons/defining-story-completion-as-a-software-tester"&gt;tell a bit more of the story&lt;/a&gt;. In the team lead experiment, I can imagine my team member telling my boss "Elizabeth told me to be quiet" or me telling my boss "The talking-dominant team member is giving room for others to contribute." Telling a slightly longer story of the journey displays my value as a team lead in a better light. &lt;/p&gt;
&lt;p&gt;What experiments are you running right now? Is something that looks or feels like a failure getting you closer to a solution? How long is your time horizon?&lt;/p&gt;&lt;/div&gt;</description><category>career</category><category>critical-thinking</category><category>humans</category><category>leadership</category><category>mindset</category><category>teaching</category><category>testing</category><guid>https://elizabethzagroba.com/posts/2021/the_long_haul/</guid><pubDate>Fri, 07 May 2021 22:00:00 GMT</pubDate></item><item><title>Questions from Exploratory Week on Writing Exploratory Testing Charters</title><link>https://elizabethzagroba.com/posts/2021/questions_from_exploratory_week_on_writing_exploratory_testing_charters/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;figure&gt;&lt;img src="https://elizabethzagroba.com/images/posts/2021/MoT.jpg"&gt;&lt;/figure&gt; &lt;div&gt;&lt;p&gt;The Ministry of Testing hosted a week all about exploratory testing. I had the honor and privilege to help shepherd a small group of testers on the path of writing charters for their exploration. The most interesting part for me is where people had questions. It helps me figure out what sunk in, what could use more explanation, and helps me know that I've answered at least one person's burning question. Here are some of the ones I remember from the live Q&amp;amp;A at the end:&lt;/p&gt;
&lt;h4&gt;Q. Do you use the word charter?&lt;/h4&gt;
&lt;p&gt;A. Basically no. I've only heard testers who've specifically dug into this topic use the word charter. Almost all of the people I collaborate with on a daily basis (developers, product owner, UX, managers, other testers) do not have this as part of their experience. Most of my colleagues are not working in their first language. As a native speaker, I need to have more than one word to describe any particular phenomenon in case the first one doesn't resonate, or isn't understandable in my accent. (Everyone has an accent.) I've called charters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;questions&lt;/li&gt;
&lt;li&gt;missions&lt;/li&gt;
&lt;li&gt;paths&lt;/li&gt;
&lt;li&gt;plans&lt;/li&gt;
&lt;li&gt;goals&lt;/li&gt;
&lt;li&gt;investigations&lt;/li&gt;
&lt;li&gt;journeys&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It's less important to use the word charter than it is to get across the intent: you're going on an exploration, in a particular direction, with specific set of tools, and you hope to come away with more information on this topic than when you set out. Sharing your charters helps you get feedback about where to look more deeply, more broadly, and &lt;a href="https://elizabethzagroba.com/posts/2020/2020-05-24_if_a_test_falls_in_a_forest/"&gt;where not to look at all&lt;/a&gt;. &lt;/p&gt;
&lt;h4&gt;Q. Where do you bring charters up?&lt;/h4&gt;
&lt;p&gt;A. Where &lt;em&gt;don't&lt;/em&gt; I bring charters up? It bleeds into conversations I have about my work. &lt;a href="https://youtu.be/SM57HMJpkZc?t=974"&gt;Sharing my work and getting feedback about it is what ensures I'm providing valuable work for my team in the right direction&lt;/a&gt;. I tend to discover points of interest for my developers once or twice a day when development is starting, and more often when testing is at its peak, which often escalates to pairing. Here are some other moments in time where I share charters: &lt;/p&gt;
&lt;h5&gt;Standup&lt;/h5&gt;
&lt;p&gt;It's how I explain what I tested yesterday, what pieces I might have time for today, and what directions I haven't or won't have time for before we want to release the story. Sharing where I'm looking prevents me from being the one gatekeeper on quality for our product. "I've successfully called the API as an admin user and a regular user. Today I'm going to dig into what happens with the non-required fields." will solicit a completely different type of feedback than "I have an hour or two left on this story."&lt;/p&gt;
&lt;h5&gt;Refinement&lt;/h5&gt;
&lt;p&gt;Any clues I can give my team about what I'll be looking into, what kind of test data I might set up, and what tools I'll be using to test a particular feature will help them figure out the whole scope of the story. "I'm going to try names at the character limit to see how they wrap on the page." helps us all figure out that we need to talk about our expectations for a character limit, we need to talk to UX about what should happen when you try to input something too long, I need to test what happens on the API side for the same field, and we might need a frontend dev to help us with the wrapping or truncation depending on what UX decides.&lt;/p&gt;
&lt;h5&gt;Testing starts executing&lt;/h5&gt;
&lt;p&gt;This is the point in time where there's enough built that I can add test execution to the setup and planning I've already been doing on a story. It might be that the API spec is published, it might be that the application has one happy path built. The developers are still going, but there's somewhere for me to start. Depending on the size and complexity of the story, I'll reflect for myself, or share my ideas with someone else on the team. If it involves an integration with another team, I'd reach out to them too. &lt;/p&gt;
&lt;h4&gt;Q. Isn't that just a test case?&lt;/h4&gt;
&lt;p&gt;A. After almost two hours of technical difficulties and explaining things, I have to say I did not write the most elegant charter as an example during the workshop. You got me! I'm glad that this workshop participant has a good feel for what is too specific or too broad. I find this so hard to explain because so much of that depends on the context. &lt;/p&gt;
&lt;p&gt;But it wasn't terribly important to me to get the level of detail correct. Charters are a place to reflect on your testing and spark conversation. This charter did exactly that. &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;You can find other questions there weren't time for during the workshop on the &lt;a href="https://club.ministryoftesting.com/t/wander-with-a-purpose-writing-charters-for-your-exploratory-test-sessions/49746"&gt;Ministry of Testing club&lt;/a&gt;. The &lt;a href="http://ezagroba.github.io/charters"&gt;slides from the workshop are on github&lt;/a&gt;. &lt;/p&gt;&lt;/div&gt;</description><category>charters</category><category>exploratory-testing</category><category>risk-based-testing</category><category>teaching</category><category>testing</category><guid>https://elizabethzagroba.com/posts/2021/questions_from_exploratory_week_on_writing_exploratory_testing_charters/</guid><pubDate>Fri, 30 Apr 2021 22:00:00 GMT</pubDate></item><item><title>The Flow of Two Exploratory Testing Sessions</title><link>https://elizabethzagroba.com/posts/2020/2020-12-26_flow_of_two_exploratory_testing_sessions/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;div&gt;&lt;p&gt;The &lt;a href="https://exploratorytesting.org/"&gt;Exploratory Testing Peer Conference&lt;/a&gt; &lt;a href="https://twitter.com/search?q=%23et19&amp;amp;src=typed_query"&gt;#ET19&lt;/a&gt; followed the 2019 Valencia edition of the European Testing Conference. I said something that I pretty immediately forgot in the upheaval when I returned to the office, but it really stuck with &lt;a href="https://twitter.com/charrett"&gt;Anne-Marie Charrett&lt;/a&gt;. I appreciate both that she remembered this at all, and continues to insist that I'm the one who had this stroke of genius when she really brought it to life. Here's the idea: &lt;/p&gt;
&lt;p&gt;It's straightforward to follow one thread or idea through an exploratory testing session. It's not straightforward to decide which path to take, feed information from one path back into another, recognize that there are different paths, or bring others along for this journey. &lt;/p&gt;
&lt;h4&gt;The Ensemble at Work&lt;/h4&gt;
&lt;p&gt;We have a weekly ensemble testing session at my workplace. For an hour and a half, testers from different teams working in the same tech stack come together to share knowledge and build testing skills. In a recent ensemble testing session, a tester on one team brought a ticket they'd been avoiding tackling on their own. They knew they didn't know how to test the fix. But they felt like they'd talked about it enough as a team that they should have understood what to do already. &lt;/p&gt;
&lt;p&gt;We read through the story with the group of testers. We determined that a static code analysis security scan had discovered vulnerabilities in a couple of libraries. The developers had fixed the issue by removing the libraries. It was our mission to make sure those libraries were removed. &lt;/p&gt;
&lt;p&gt;Immediately a plan came to my mind:
1. Map out what kinds of pages there were, assuming that different pages of the same type would be likely to load the same libraries: list view, detail view, landing page, etc. 
1. Look at one of each of those pages with the Network tab open in the developer tools.&lt;/p&gt;
&lt;p&gt;In a quick spirt of excitement, I dumped this idea on the group without figuring out if people knew what either of these things meant. (It turns out, not everyone did.) But everyone seemed to understand that there was somewhere in the developer tools where we could tell which libraries were loaded, so we started there. Exploring in a group is not about getting everyone to follow my idea immediately (&lt;a href="https://www.showingupforracialjustice.org/white-supremacy-culture-characteristics.html"&gt;or ever&lt;/a&gt;), it's about making sure everyone is on board and understands what's going on.&lt;/p&gt;
&lt;p&gt;Proving the absence of a thing is harder than proving the presence of something, so we spent a bit of time looking through the Console and Storage tabs, as well as reloading the page with the Network tab opened, to figure out what appeared where. That helped everyone remember or discover that we didn't need to reload the page if the Network tab was open before the page loaded. This sped us up for the rest of the session.&lt;/p&gt;
&lt;p&gt;Next, we looked at a couple of similar-looking list pages. We searched for the libraries in the Network tab. They weren't there. Now that we'd seen a couple of examples, I decided it was the right time to bring up my original idea of grouping pages by type. (Going from the abstract to the concrete doesn't work for everybody, so sometimes going from the concrete to the abstract works better.) I asked "These last two pages both looked like list pages, what other kinds of pages are there? Can we list them? Should we look at a detail page?" This comment blew the mind of the tester who brought this ticket. They'd been testing this product for two years and had never organized the product this way in their brain. It may not have occurred to them that a product &lt;em&gt;could&lt;/em&gt; be organized in different ways in their thoughts depending on the circumstance. We got as far as listing the concrete pages we'd checked, but not as far as identifying all the types in the abstract before the energy in the ensemble moved on.&lt;/p&gt;
&lt;p&gt;We looked at a detail page. We looked at a settings page. Then one of the testers who's been looking at a lot of front-end Javascript noticed two things: both the URLs we were searching for had &lt;code&gt;ajax&lt;/code&gt; in them, so we only needed to search for one thing on each page we opened. And second, they knew that ajax was used to make changes to pages that had already loaded, so they asked "what kinds of pages change after they're loaded?" In this particular application, it was mostly forms in pop-up windows, so we concentrated our efforts there for the rest of the session. &lt;/p&gt;
&lt;p&gt;The whole session took about an hour and a half. A tester that came in scared and confused left empowered, with information to bring to their developers, and  a plan for how to execute the rest of the testing. Here's one way of looking at our exploratory testing session:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://elizabethzagroba.com/images/posts/2020/work-ensemble.png"&gt;&lt;img src="https://elizabethzagroba.com/images/posts/2020/work-ensemble.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;At every stage, we absorbed a lesson as a group, and used it as our new superpower to make our testing better for the next bit. There were other paths we could have pursued, but many of these weren't consciously mentioned or acknowledged during the session.&lt;/p&gt;
&lt;h4&gt;The Ensemble at the Conference&lt;/h4&gt;
&lt;p&gt;I facilitated a couple of ensemble sessions with groups at Agile Testing Days. Our first emsemble had a couple people drop out, so it ended up being one tester, one developer, and me. We were looking at a &lt;a href="https://eviltester.github.io/TestingApp/apps/7charval/simple7charvalidation.htm"&gt;very straightforward application&lt;/a&gt; from Alan Richardson where you can decide whether a string contains 7 characters and is valid (in the set A-Z, a-z, 0-9, and * ). A few different times the developer and I asked if we should look at the source code. Rather than trying to interrogate the application based on the behavior from different inputs (black box testing), we wanted to go to the source (white box testing). &lt;/p&gt;
&lt;p&gt;But we never did. We kept trying different inputs, getting increasingly creative with order, special characters, Unicode characters, other languages as we progressed. But we never chose a different path. Even as I tried to encourage us to take notes so we wouldn't try the same things we'd already tried, we didn't. &lt;/p&gt;
&lt;p&gt;&lt;a href="https://elizabethzagroba.com/images/posts/2020/atd-ensemble.png"&gt;&lt;img src="https://elizabethzagroba.com/images/posts/2020/atd-ensemble.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;We did manage to find a good resource for copying and pasting unicode characters, but we didn't learn how to explore the application more efficiently, or take what we learned earlier in the session to apply it to the rest of the session.&lt;/p&gt;
&lt;h4&gt;The Power of Exploratory Testing&lt;/h4&gt;
&lt;p&gt;Brute force will get you somewhere. Trying enough different inputs, or different pages, and you'll gather more information about how the application works. But the power of exploratory testing comes from learning from your earlier results. It's realizing there are different ways to go, different paths to follow, jumping on one of those while it serves you, and making sure everyone else is along for the ride. &lt;/p&gt;&lt;/div&gt;</description><category>exploratory-testing</category><category>teaching</category><category>testing</category><guid>https://elizabethzagroba.com/posts/2020/2020-12-26_flow_of_two_exploratory_testing_sessions/</guid><pubDate>Fri, 25 Dec 2020 23:00:00 GMT</pubDate></item></channel></rss>