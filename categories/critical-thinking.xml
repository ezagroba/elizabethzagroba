<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Elizabeth Zagroba: Software Tester (Posts about critical-thinking)</title><link>https://elizabethzagroba.com/</link><description></description><atom:link href="https://elizabethzagroba.com/categories/critical-thinking.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Â© 2021 &lt;a href="mailto:me@elizabethzagroba.com"&gt;Elizabeth Zagroba&lt;/a&gt; Mozilla Public License 2.0</copyright><lastBuildDate>Tue, 18 May 2021 15:46:48 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>The Long Haul</title><link>https://elizabethzagroba.com/posts/2021/the_long_haul/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;div&gt;&lt;p&gt;I've been both the lead of my team and a tester on that team for a year now. Getting answers, adapting to change, and identifying solutions have completely different time horizons in each of these roles. &lt;/p&gt;
&lt;hr&gt;
&lt;h4&gt;Tester experiments&lt;/h4&gt;
&lt;p&gt;Testing experiments can run quickly. A testing experiment might look like this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Call an API&lt;/li&gt;
&lt;li&gt;Inspect the output&lt;/li&gt;
&lt;li&gt;Compare that to the specification&lt;/li&gt;
&lt;li&gt;Question whether either or both need changing&lt;/li&gt;
&lt;li&gt;Talk to a developer about the changes&lt;/li&gt;
&lt;li&gt;Update the specification and/or tests&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;All of that happens within minutes or hours, or days if schedules are extremely incompatible and asynchronous communication is failing. I can be confident in the experiment's outcome. I can weigh the relative merits of caring vs. not caring about a particular error response code or required field, and leave my work at work. The next time I see a particular error response, I know what to look for and where changes might be needed. A failing test is evidence that something used to work in a particular way. &lt;/p&gt;
&lt;h4&gt;Team lead experiments&lt;/h4&gt;
&lt;p&gt;Team lead experiments take longer. A team lead experiment might look something more like this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Team members complain that it's hard to get their ideas in during refinement.&lt;/li&gt;
&lt;li&gt;I mention this to the talking-dominant team member at a 1-on-1.&lt;/li&gt;
&lt;li&gt;Talking-dominant team member dominates following refinement.&lt;/li&gt;
&lt;li&gt;I remind talking-dominant team member in Slack about our previous conversation.&lt;/li&gt;
&lt;li&gt;Talking-dominant team member spills over their allotted time during big unit meeting.&lt;/li&gt;
&lt;li&gt;I bring both of these instances in our 1-on-1, sharing the consequences (they're the single point of failure, other team members aren't heard) of their actions.&lt;/li&gt;
&lt;li&gt;Talking-dominant team member does it again.&lt;/li&gt;
&lt;li&gt;I ask team member what I can do to help them change their behavior, given that we are both adults in control of our own behavior. They agree that change is their responsibility. We agree that setting their microphone on mute at the start of the meeting would help.&lt;/li&gt;
&lt;li&gt;Talking-dominant team member dominates some of the following refinement, until I remind them to mute, after which other team members have time to think and contribute too.&lt;/li&gt;
&lt;li&gt;I ask talking-dominant team member to set up a Slackbot to send them a reminder to mute their microphone each week before the meeting.&lt;/li&gt;
&lt;li&gt;Other people are able to contribute at the following refinement. &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This took place over months. We're not to a point where we have a solution that works every time. I went in with a different hypothesis each time, not knowing when I'd hit on the right one:&lt;/p&gt;
&lt;p&gt;2. I think the talking-dominant team member isn't aware of their behavior.&lt;br&gt;
4. I think the team member has forgotten our first conversation.&lt;br&gt;
6. I think the team member doesn't understand the impact of their behavior.&lt;br&gt;
8. I think the team member hasn't found a tool or a trigger to change their habit.&lt;br&gt;
10. I think the team member needs both a tool and a trigger to change their habit.&lt;/p&gt;
&lt;p&gt;Any of the first four experiments taken by itself looks like a failure. The talking-dominant team member prevents other team members from contributing effectively. It takes me time as a leader to come up with a different hypothesis, try something else, and discover where to go from there. And this was a relatively straightforward issue to assess. Imagine how long it might take to find an effective response to a problem with more variables and more consequences.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;I'm also thinking not just about the experiments themselves, but how they might come across to the wider team. For the testing experiment, I could present my results in standup the next day as "I tested it, everything's good" but it's more valuable for everyone if I &lt;a href="https://www.ministryoftesting.com/dojo/lessons/defining-story-completion-as-a-software-tester"&gt;tell a bit more of the story&lt;/a&gt;. In the team lead experiment, I can imagine my team member telling my boss "Elizabeth told me to be quiet" or me telling my boss "The talking-dominant team member is giving room for others to contribute." Telling a slightly longer story of the journey displays my value as a team lead in a better light. &lt;/p&gt;
&lt;p&gt;What experiments are you running right now? Is something that looks or feels like a failure getting you closer to a solution? How long is your time horizon?&lt;/p&gt;&lt;/div&gt;</description><category>career</category><category>critical-thinking</category><category>humans</category><category>leadership</category><category>mindset</category><category>teaching</category><category>testing</category><guid>https://elizabethzagroba.com/posts/2021/the_long_haul/</guid><pubDate>Fri, 07 May 2021 22:00:00 GMT</pubDate></item><item><title>Recently Encountered Logical Fallacies</title><link>https://elizabethzagroba.com/posts/2021/recently_encountered_logical_falacies/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;figure&gt;&lt;img src="https://elizabethzagroba.com/images/posts/2021/statue.jpg"&gt;&lt;/figure&gt; &lt;div&gt;&lt;p&gt;I was on &lt;a href="https://www.ministryoftesting.com/dojo/lessons/discussion-critical-thinking"&gt;a panel about critical thinking for the Ministry of Testing&lt;/a&gt; last week. One of my fellow panelists and commendable ranter &lt;a href="https://twitter.com/Maaikees"&gt;Maaike Brinkoff&lt;/a&gt; brought up &lt;em&gt;ad hominem&lt;/em&gt; (personal) attacks as one example of a failure of critical thinking. It's one of many &lt;a href="https://fallacyinlogic.com/"&gt;logical fallacies&lt;/a&gt; that are worth exploring further. &lt;/p&gt;
&lt;p&gt;Equipping yourself with the name for a thing helps you recognize it when it appears. (Lara Hogan wrote recently about applying the skill, of &lt;a href="https://leaddev.com/communication-relationships/skill-naming-whats-happening-room"&gt;being able to name the problem in the room&lt;/a&gt;, to defuse tense meetings.) These are some of the fallacies I've across recently when I've been debriefing testing sessions, facilitating refinement sessions, and reviewing conference submissions.&lt;/p&gt;
&lt;h4&gt;Affirming the consequent&lt;/h4&gt;
&lt;p&gt;Affirming the consequent is applying a conditional without the conditionality, or assuming something happened because you see a result. &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;If P (I run the pipeline) then Q (the latest build will be available on the test environment)&lt;/li&gt;
&lt;li&gt;Q (the latest build is available on the test environment)&lt;/li&gt;
&lt;li&gt;Therefore P (I ran the pipeline) &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We can't assume the converse: if Q, then P. Just because the latest build is on the test environment doesn't mean I ran the pipeline. Maybe someone else ran the pipeline, or put the build there manually. Maybe there haven't been any changes since yesterday, and the build from yesterday is still the latest one.&lt;/p&gt;
&lt;h4&gt;Fallacy of composition&lt;/h4&gt;
&lt;p&gt;This assumes that something that applies to one member of a class applies to them all.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Y is part of X (Stephanie is an admin user)&lt;/li&gt;
&lt;li&gt;Y has property P (Stephanie can see this page)&lt;/li&gt;
&lt;li&gt;X has property P (any admin user can see this page)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We can't assume that what's true for one member of a class applies to all of them. What happens if Stephanie can be assigned more than one role, a more restrictive/regular user role in addition to the admin role? Can she still see it? What if Stephanie being able to see the page has nothing to do with her status as an admin user?&lt;/p&gt;
&lt;h4&gt;&lt;em&gt;Post hoc ergo propter hoc&lt;/em&gt; (correlation without causation)&lt;/h4&gt;
&lt;p&gt;This one is easiest to see when others are debreifing their testing to me, but I've also learned to catch for myself. &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Event A occurred (I clicked the button)&lt;/li&gt;
&lt;li&gt;Then event B occurred (a whole bunch of log messages appeared)&lt;/li&gt;
&lt;li&gt;Therefore A caused B (clicking the button caused a whole bunch of log messages)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We can't assume that events that occur in a particular sequence in time are necessarily causal. Did clicking the button trigger the log messages? What do the log messages say? Did you read them? Who else could be using this environment? Does the same thing happen every time you click the button, or when you run the application in a different environment? &lt;/p&gt;
&lt;h4&gt;Argument from repetition&lt;/h4&gt;
&lt;p&gt;When someone says the same thing enough times, or brings up the same unimportant issue in a refinement meeting week after week, it can become easier to address the issue rather than convincing them yet again why it's not a priority. I've been facilitating refinement meetings every week for my teams for the past two years. &lt;a href="https://butyoudontlooksick.com/articles/written-by-christine/the-spoon-theory/"&gt;I only have a finite amount of energy&lt;/a&gt; that is not always worth expending by refuting the case for a small edge case week after week. &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Shoutout to my logic professor Dan Cohen at Colby College, who had us memorize and distinguish logical fallacies as part of his brilliant Logic and Argumentation course, and pointing out that an ease and comfort with truth tables would translate well to a computer science course. Special thanks to Joep Schuurkes for his philosophical and technological opinions on this piece.&lt;/p&gt;&lt;/div&gt;</description><category>critical-thinking</category><category>logic</category><category>naming</category><category>testing</category><guid>https://elizabethzagroba.com/posts/2021/recently_encountered_logical_falacies/</guid><pubDate>Tue, 30 Mar 2021 22:00:00 GMT</pubDate></item></channel></rss>