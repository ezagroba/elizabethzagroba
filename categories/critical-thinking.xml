<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Elizabeth Zagroba: Organizational Anarchist (Posts about critical-thinking)</title><link>https://elizabethzagroba.com/</link><description></description><atom:link href="https://elizabethzagroba.com/categories/critical-thinking.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Â© 2022 &lt;a href="mailto:me@elizabethzagroba.com"&gt;Elizabeth Zagroba&lt;/a&gt; Mozilla Public License 2.0</copyright><lastBuildDate>Sun, 27 Feb 2022 18:55:43 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>This Diagram Asked More Questions Than It Answered</title><link>https://elizabethzagroba.com/posts/2022/01_16_this_diagram_asked_more_questions_than_it_answered/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;p&gt;I made a diagram that asked more questions than it answered.&lt;/p&gt;
&lt;p&gt;As Quality Lead for the seven engineering teams in my unit, I'm tasked with getting developers to think more holistically. I'm not an expert in any of the individual parts of the product teams are. I aim to have a bird's eye view on the whole, particularly when it comes to the testing we're doing. Each team is thinking about thorough coverage of their part; I'm looking at the through-line across the products.&lt;/p&gt;
&lt;p&gt;So after only a few weeks on the job, when a particular behavior got the software development managers asking me "Did anyone test this end-to-end?" all I could say for sure was "I haven't!" It did get me thinking and asking them though:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What do you mean when you say end-to-end?&lt;/li&gt;
&lt;li&gt;Did you mean an automated test, or someone trying it at least once manually? &lt;/li&gt;
&lt;li&gt;Is the one path I have in mind the same one you're picturing?&lt;/li&gt;
&lt;li&gt;Is it important to have some type of coverage over every possible path, or can we decide to focus on the risky ones?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I started by drawing what I had in mind. It looked like this. The colored boxes show which team owns the code. The outlined boxes show actions a user could take. &lt;/p&gt;
&lt;p&gt;&lt;span class="img_container" style="display: inline-block;"&gt;&lt;img alt="" src="https://elizabethzagroba.com/images/posts/2022/step1.png" style="display:block; margin-left: auto; margin-right: auto;" title="A humble beginning"&gt;&lt;span class="img_caption" style="display: block; text-align: center;"&gt;A humble beginning&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;I went to it show people all around the department (developers, testers, product, UX, analytics, managers) so they could tell me where I was wrong or needed more detail. (&lt;a href="https://elizabethzagroba.com/posts/2017/2017-08-06_doubt-builds-trust/"&gt;More on how that builds credibility in this post&lt;/a&gt;). &lt;/p&gt;
&lt;p&gt;Each person I showed it to added more boxes, or split existing boxes into more specific actions. Some even added more teams. I approached the teams humbly, acknowledging that though I was being asked about end-to-end testing, I didn't have a good view on what that meant right now. I acknowledged that they were the experts in the their own domains. I'd reviewed roadmaps and documentation to do what I could before I spoke to them so they only had to offer corrections instead of whole explanations. And I thanked them for correcting my ignorance and blind spots as we updated the diagram together. &lt;/p&gt;
&lt;p&gt;To our analytics expert, I said "I get asked a lot about the end-to-end flow, but I'm not sure what that means exactly. Do you have the same problem?" A wave of common struggle and understanding washed over them. &lt;/p&gt;
&lt;p&gt;By the time 15 people had given their perspective, the diagram had exploded into this monstrosity. &lt;/p&gt;
&lt;p&gt;&lt;span class="img_container" style="display: inline-block;"&gt;&lt;img alt="" src="https://elizabethzagroba.com/images/posts/2022/step2.png" style="display:block; margin-left: auto; margin-right: auto;" title="A completely overwhelming mess"&gt;&lt;span class="img_caption" style="display: block; text-align: center;"&gt;A completely overwhelming mess&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This diagram was hard to read. It wasn't clear (to anyone but me) where the entry and exit points where. The key was hard to reference and had too much explanation. At a glance, the main takeaway was "This is complicated." This did live up to one of my goals: get people to see that "test everything end-to-end" is not a straightforward, single path. We wouldn't test every path or promise full coverage from the start (or ever, but that's &lt;a href="https://elizabethzagroba.com/posts/2020/2020-05-24_if_a_test_falls_in_a_forest/"&gt;another conversation&lt;/a&gt;). But we could say: "There's a lot to cover here. Let's choose the most important path to start."&lt;/p&gt;
&lt;p&gt;In showing the diagram to our sales and UX experts, and again acknowledging that this kind of diagramming was more their expertise than mine, I got nudged in the direction of business process modelling notation. I kept my teams and user actions in a way that notation didn't imagine, but putting everything in rows and columns gave my diagram an air of professionalism it didn't have before. &lt;/p&gt;
&lt;p&gt;&lt;span class="img_container" style="display: inline-block;"&gt;&lt;img alt="" src="https://elizabethzagroba.com/images/posts/2022/step3.png" style="display:block; margin-left: auto; margin-right: auto;" title="Something bordering on approachable"&gt;&lt;span class="img_caption" style="display: block; text-align: center;"&gt;Something bordering on approachable&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;A different UX expert said they'd been too overwhelemed to try to process my overwhelming mess of a diagram, but they'd been able to read and learn from this attempt. &lt;/p&gt;
&lt;p&gt;Our software development managers and product experts were the ones asking about the state of end-to-end testing initially. Showing them the diagram got them thinking on the exactly the paths I wanted to trigger: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Can we have one of these for a different product we're building?&lt;/li&gt;
&lt;li&gt;What would this diagram look like if we only followed one user persona's journey?&lt;/li&gt;
&lt;li&gt;What else might be included in end-to-end if we think outside the scope of the seven engineering teams in our unit?&lt;/li&gt;
&lt;li&gt;How do people buy the product? How are they onboarded?&lt;/li&gt;
&lt;li&gt;How do people learning how to use the product discover these steps you've outlined? How do they know which direction they want to go?&lt;/li&gt;
&lt;li&gt;How do people make decisions at these decision points? How can we gain more insight into how they're doing that?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I think I probably could have helped perform some end-to-end testing with a collection of testers from the three teams I initially identifed in my first diagram, gone back to the managers and proclaimed "yes, we're end-to-end testing." But my job isn't to provide simple answers. It's to get people thinking about the whole, and asking the important questions for themselves. The journey of this diagram did exactly that. &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Do you find yourself answering questions that you see as misguided? How can you guide people to ask better questions? &lt;/p&gt;</description><category>critical-thinking</category><category>dependencies</category><category>testing</category><guid>https://elizabethzagroba.com/posts/2022/01_16_this_diagram_asked_more_questions_than_it_answered/</guid><pubDate>Sat, 15 Jan 2022 23:00:00 GMT</pubDate></item><item><title>Give Them the Fish, Then Teach Them to Fish</title><link>https://elizabethzagroba.com/posts/2021/give_them_the_fish_then_teach_them_to_fish/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;p&gt;A colleague came to me with a request the other day. I didn't handle it quite how I wanted to. The request went something like this:&lt;/p&gt;
&lt;p&gt;"I remember you were on the team for Big Scary product a couple years ago. Do you know if I can delete this List of Stuff from Big Scary product, and if I can automate that?"&lt;/p&gt;
&lt;p&gt;I did not know. It was two years ago. Big Scary product had gotten Bigger and Scarier in the meantime. &lt;/p&gt;
&lt;p&gt;But I knew where my team linked to our API specs from our customer-facing documentation. I applied the same principle to discover where Big Scary product API specs were. I looked at those specs and found the List of Stuff in a response body for an API call, but noticed that my colleague wouldn't have the ID the request required. So I looked at the API specs from a Bigger Scarier product. Combining a call from there would get the ID Big Scary product needed.&lt;/p&gt;
&lt;p&gt;I was short on time, so I answered the question directly. I said it was possible, and possible to automate, and provided the links to the specs for both products. My colleague thanked me, and left the conversation able to solve their problem quickly. &lt;/p&gt;
&lt;p&gt;I gave them the fish. What they learned from that interaction was: Elizabeth knows where to find stuff. I can come to her when I don't know how to find stuff and she will find it for me. That was the wrong lesson. &lt;/p&gt;
&lt;h3&gt;Give Them the Fish, Then Teach Them to Fish&lt;/h3&gt;
&lt;p&gt;A better lesson would have been: I know where to look for things. Elizabeth will give me the tools to know where to look, and empower me to do so. Now that I've got the access and seen it done once before, I can take a few more steps before I reach out Elizabeth the next time.&lt;/p&gt;
&lt;p&gt;Here's what I could have done to get to get this colleague there:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Explain where all the API specs live: I could have explained my thought process for finding the API specs, showed how I navigate using the headers and &lt;code&gt;Ctrl + F&lt;/code&gt; on the page, and compare the requests and responses to what's needed.&lt;/li&gt;
&lt;li&gt;Update them about who's on the team for Big Scary product now: I could have listed a few team members names who I knew were working on Big Scary product, or pointed my colleague to the Slack channel for the whole team.&lt;/li&gt;
&lt;li&gt;Introduce colleague to a member of the team for Big Scary product: Since this colleague was a tester, I could have started a direct message with them and the tester on the team for Big Scary product, copying the question from the DM I first received. &lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;What If I Only Teach Them to Fish?&lt;/h3&gt;
&lt;p&gt;What would have happened if I'd skipped what I'd done, and withheld the links to the API specs? &lt;/p&gt;
&lt;p&gt;I wouldn't have been able to guarantee that my colleague was in the learning zone. From what I knew about their situation, they were accumulating a lot of data that they wanted to delete. I didn't know what other pressures were coming from the team, but the need to automate it suggested it was a bigger problem than just a few extra entries in a database. &lt;/p&gt;
&lt;p&gt;Giving my colleague the fish, and &lt;em&gt;then&lt;/em&gt; teaching them to fish, relieves any of that pressure to deliver, and helps open them up to learning and growing. &lt;/p&gt;
&lt;h3&gt;Tell Them What You're Doing&lt;/h3&gt;
&lt;p&gt;Some colleagues are distracted, or dense, or not able to take away &lt;a href="https://elizabethzagroba.com/posts/2021/delivering_information_vs_delivering_meta_information/"&gt;meta-information&lt;/a&gt; from a conversation along with the information. They may stop listening after they have the answer. &lt;/p&gt;
&lt;p&gt;Combat this by sharing your motives. Remind them that you too are busy. Explain that your goal is to empower them. Encourage them to reach out to the team working on Big Scary product, so that those team members can also get good at knowing where to look and answering colleagues' questions. Tell them you're happy to help them again, but you'll expect more details of what they tried first. Then hold them to that. &lt;/p&gt;
&lt;p&gt;The best lesson is: I want to take a few more steps next time I have a problem, because I know I can, and Elizabeth expects more from me. &lt;/p&gt;</description><category>critical-thinking</category><category>leadership</category><category>mindset</category><category>teaching</category><category>testing</category><guid>https://elizabethzagroba.com/posts/2021/give_them_the_fish_then_teach_them_to_fish/</guid><pubDate>Sat, 07 Aug 2021 22:00:00 GMT</pubDate></item><item><title>Complete the Main Quest First</title><link>https://elizabethzagroba.com/posts/2021/complete_the_main_quest_first/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;p&gt;Recently, I made an outline for a tester (who was still onboarding) for what kinds of things to test on a new API endpoint we added. They explored, wrote a bunch of automated tests to capture their work, and came back with a list of interesting and good catches in the error responses. My first question in our debrief was: did you try a successful response? They hadn't. I sent them back to tackle that too. &lt;/p&gt;
&lt;p&gt;Because a successful response is the first thing our product owner is going to ask about. That's what we'd want to show off at the review meeting internally to demonstrate the new API endpoint. That's the first the customer is going to try. They're going to copy the request from our OpenAPI specification, paste it in Postman (or the tool of their choice, but our customers so far have been using Postman), and see if their credentials will get them the response that matches the specification. These stakeholders share a common concern, and that's the risk we should be migitating with testing. First. &lt;/p&gt;
&lt;h3&gt;Complete the main quest first.&lt;/h3&gt;
&lt;p&gt;Complete the main quest first. Come back to the side quests. &lt;/p&gt;
&lt;p&gt;A customer had asked for this API endpoint to be added. If we'd tested the happy path first, we would have had the option of releasing the API for the customer to use. The risk of discovering a successful request wouldn't yield a successful response was relatively low in this case, since our developers tend to try one happy path themselves.&lt;/p&gt;
&lt;p&gt;But what if the main quest had required a lot of setup, explanations to build knowledge and context for the onboarding tester, or yielded an issue? I'd done a risk-based analysis of what all to complete as part of our definition of done for this story. But I hadn't shared my approach to completing the main quest first, so the tester did what testers do, and went on a hunt to find weird stuff. &lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://elizabethzagroba.com/images/posts/2021/iceland.jpg"&gt;&lt;/p&gt;
&lt;h3&gt;Note down and follow-up on werid stuff; do not get distracted by it&lt;/h3&gt;
&lt;p&gt;Software will break in all sorts of ways. The more time and curiosity you have to dig into it, the more you'll discover. But are those the most important things? &lt;/p&gt;
&lt;p&gt;In this API, the tester discovered that if you paste 10,000 characters into a field that's meant for a UUID, you get a 400 response. But did they try a regular old UUID first? What if they get a 400 response no matter what they put in that field, because the field name in the specification doesn't match what's in the code? Is trying 10,000 characters the first and biggest risk they have to face when presenting this API to a customer?&lt;/p&gt;
&lt;p&gt;I'm not saying don't try 10,000 characters. &lt;a href="https://twitter.com/ezagroba/status/1234822805709053953"&gt;I love that shit&lt;/a&gt;. But decide if it's a risk you care about first. &lt;a href="https://elizabethzagroba.com/posts/2020/2020-05-24_if_a_test_falls_in_a_forest/"&gt;If you don't care about the outcome, don't test it&lt;/a&gt;. Don't make busy-work for yourself just to fill the time. &lt;/p&gt;
&lt;h3&gt;Make side quests a concious choice&lt;/h3&gt;
&lt;p&gt;Before you start throwing 10,000 characters at your API, talk to your team. Your developer can probably tell you if they never built something to deal with that situation. Your product owner can tell you they'd rather have it to the customer sooner. Your data analyst can tell you if there's already longer stuff than that in the database, or if you should be trying Japanese instead. &lt;/p&gt;
&lt;p&gt;Make side quests a deliberate choice. Share them to increase their value or figure out who on the team is best-suited to execute them. &lt;/p&gt;
&lt;h3&gt;Recognize when the quest is a journey, not a destination&lt;/h3&gt;
&lt;p&gt;Throwing 10,000 characters at an API may be a way to start a discussion about the speed at which responses are returned. It might be a way of showing &lt;a href="http://coffeeipsum.com/"&gt;your favorite random text generator&lt;/a&gt; to your fellow tester. It might be an exercise at an ensemble testing session, where everyone can practice pausing before executing an idea to describe the expected behavior first. &lt;/p&gt;
&lt;p&gt;Quests can be valuable in ways that are not directly related to the finishing the quest. &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note: I got asked recently if I use the word charter much with non-testers. I don't. Try reading this again but replacing every mention of "quest" with "charter".&lt;/em&gt;&lt;/p&gt;</description><category>charters</category><category>critical-thinking</category><category>exploratory-testing</category><category>mindset</category><category>reporting</category><category>risk-based-testing</category><category>testing</category><guid>https://elizabethzagroba.com/posts/2021/complete_the_main_quest_first/</guid><pubDate>Sat, 03 Jul 2021 22:00:00 GMT</pubDate></item><item><title>The Long Haul</title><link>https://elizabethzagroba.com/posts/2021/the_long_haul/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;p&gt;I've been both the lead of my team and a tester on that team for a year now. Getting answers, adapting to change, and identifying solutions have completely different time horizons in each of these roles. &lt;/p&gt;
&lt;hr&gt;
&lt;h4&gt;Tester experiments&lt;/h4&gt;
&lt;p&gt;Testing experiments can run quickly. A testing experiment might look like this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Call an API&lt;/li&gt;
&lt;li&gt;Inspect the output&lt;/li&gt;
&lt;li&gt;Compare that to the specification&lt;/li&gt;
&lt;li&gt;Question whether either or both need changing&lt;/li&gt;
&lt;li&gt;Talk to a developer about the changes&lt;/li&gt;
&lt;li&gt;Update the specification and/or tests&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;All of that happens within minutes or hours, or days if schedules are extremely incompatible and asynchronous communication is failing. I can be confident in the experiment's outcome. I can weigh the relative merits of caring vs. not caring about a particular error response code or required field, and leave my work at work. The next time I see a particular error response, I know what to look for and where changes might be needed. A failing test is evidence that something used to work in a particular way. &lt;/p&gt;
&lt;h4&gt;Team lead experiments&lt;/h4&gt;
&lt;p&gt;Team lead experiments take longer. A team lead experiment might look something more like this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Team members complain that it's hard to get their ideas in during refinement.&lt;/li&gt;
&lt;li&gt;I mention this to the talking-dominant team member at a 1-on-1.&lt;/li&gt;
&lt;li&gt;Talking-dominant team member dominates following refinement.&lt;/li&gt;
&lt;li&gt;I remind talking-dominant team member in Slack about our previous conversation.&lt;/li&gt;
&lt;li&gt;Talking-dominant team member spills over their allotted time during big unit meeting.&lt;/li&gt;
&lt;li&gt;I bring both of these instances in our 1-on-1, sharing the consequences (they're the single point of failure, other team members aren't heard) of their actions.&lt;/li&gt;
&lt;li&gt;Talking-dominant team member does it again.&lt;/li&gt;
&lt;li&gt;I ask team member what I can do to help them change their behavior, given that we are both adults in control of our own behavior. They agree that change is their responsibility. We agree that setting their microphone on mute at the start of the meeting would help.&lt;/li&gt;
&lt;li&gt;Talking-dominant team member dominates some of the following refinement, until I remind them to mute, after which other team members have time to think and contribute too.&lt;/li&gt;
&lt;li&gt;I ask talking-dominant team member to set up a Slackbot to send them a reminder to mute their microphone each week before the meeting.&lt;/li&gt;
&lt;li&gt;Other people are able to contribute at the following refinement. &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This took place over months. We're not to a point where we have a solution that works every time. I went in with a different hypothesis each time, not knowing when I'd hit on the right one:&lt;/p&gt;
&lt;p&gt;2. I think the talking-dominant team member isn't aware of their behavior.&lt;br&gt;
4. I think the team member has forgotten our first conversation.&lt;br&gt;
6. I think the team member doesn't understand the impact of their behavior.&lt;br&gt;
8. I think the team member hasn't found a tool or a trigger to change their habit.&lt;br&gt;
10. I think the team member needs both a tool and a trigger to change their habit.&lt;/p&gt;
&lt;p&gt;Any of the first four experiments taken by itself looks like a failure. The talking-dominant team member prevents other team members from contributing effectively. It takes me time as a leader to come up with a different hypothesis, try something else, and discover where to go from there. And this was a relatively straightforward issue to assess. Imagine how long it might take to find an effective response to a problem with more variables and more consequences.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;I'm also thinking not just about the experiments themselves, but how they might come across to the wider team. For the testing experiment, I could present my results in standup the next day as "I tested it, everything's good" but it's more valuable for everyone if I &lt;a href="https://www.ministryoftesting.com/dojo/lessons/defining-story-completion-as-a-software-tester"&gt;tell a bit more of the story&lt;/a&gt;. In the team lead experiment, I can imagine my team member telling my boss "Elizabeth told me to be quiet" or me telling my boss "The talking-dominant team member is giving room for others to contribute." Telling a slightly longer story of the journey displays my value as a team lead in a better light. &lt;/p&gt;
&lt;p&gt;What experiments are you running right now? Is something that looks or feels like a failure getting you closer to a solution? How long is your time horizon?&lt;/p&gt;</description><category>career</category><category>critical-thinking</category><category>humans</category><category>leadership</category><category>mindset</category><category>teaching</category><category>testing</category><guid>https://elizabethzagroba.com/posts/2021/the_long_haul/</guid><pubDate>Fri, 07 May 2021 22:00:00 GMT</pubDate></item><item><title>Recently Encountered Logical Fallacies</title><link>https://elizabethzagroba.com/posts/2021/recently_encountered_logical_falacies/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;figure&gt;&lt;img src="https://elizabethzagroba.com/images/posts/2021/statue.jpg"&gt;&lt;/figure&gt; &lt;p&gt;I was on &lt;a href="https://www.ministryoftesting.com/dojo/lessons/discussion-critical-thinking"&gt;a panel about critical thinking for the Ministry of Testing&lt;/a&gt; last week. One of my fellow panelists and commendable ranter &lt;a href="https://twitter.com/Maaikees"&gt;Maaike Brinkoff&lt;/a&gt; brought up &lt;em&gt;ad hominem&lt;/em&gt; (personal) attacks as one example of a failure of critical thinking. It's one of many &lt;a href="https://fallacyinlogic.com/"&gt;logical fallacies&lt;/a&gt; that are worth exploring further. &lt;/p&gt;
&lt;p&gt;Equipping yourself with the name for a thing helps you recognize it when it appears. (Lara Hogan wrote recently about applying the skill, of &lt;a href="https://leaddev.com/communication-relationships/skill-naming-whats-happening-room"&gt;being able to name the problem in the room&lt;/a&gt;, to defuse tense meetings.) These are some of the fallacies I've across recently when I've been debriefing testing sessions, facilitating refinement sessions, and reviewing conference submissions.&lt;/p&gt;
&lt;h4&gt;Affirming the consequent&lt;/h4&gt;
&lt;p&gt;Affirming the consequent is applying a conditional without the conditionality, or assuming something happened because you see a result. &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;If P (I run the pipeline) then Q (the latest build will be available on the test environment)&lt;/li&gt;
&lt;li&gt;Q (the latest build is available on the test environment)&lt;/li&gt;
&lt;li&gt;Therefore P (I ran the pipeline) &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We can't assume the converse: if Q, then P. Just because the latest build is on the test environment doesn't mean I ran the pipeline. Maybe someone else ran the pipeline, or put the build there manually. Maybe there haven't been any changes since yesterday, and the build from yesterday is still the latest one.&lt;/p&gt;
&lt;h4&gt;Fallacy of composition&lt;/h4&gt;
&lt;p&gt;This assumes that something that applies to one member of a class applies to them all.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Y is part of X (Stephanie is an admin user)&lt;/li&gt;
&lt;li&gt;Y has property P (Stephanie can see this page)&lt;/li&gt;
&lt;li&gt;X has property P (any admin user can see this page)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We can't assume that what's true for one member of a class applies to all of them. What happens if Stephanie can be assigned more than one role, a more restrictive/regular user role in addition to the admin role? Can she still see it? What if Stephanie being able to see the page has nothing to do with her status as an admin user?&lt;/p&gt;
&lt;h4&gt;&lt;em&gt;Post hoc ergo propter hoc&lt;/em&gt; (correlation without causation)&lt;/h4&gt;
&lt;p&gt;This one is easiest to see when others are debreifing their testing to me, but I've also learned to catch for myself. &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Event A occurred (I clicked the button)&lt;/li&gt;
&lt;li&gt;Then event B occurred (a whole bunch of log messages appeared)&lt;/li&gt;
&lt;li&gt;Therefore A caused B (clicking the button caused a whole bunch of log messages)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We can't assume that events that occur in a particular sequence in time are necessarily causal. Did clicking the button trigger the log messages? What do the log messages say? Did you read them? Who else could be using this environment? Does the same thing happen every time you click the button, or when you run the application in a different environment? &lt;/p&gt;
&lt;h4&gt;Argument from repetition&lt;/h4&gt;
&lt;p&gt;When someone says the same thing enough times, or brings up the same unimportant issue in a refinement meeting week after week, it can become easier to address the issue rather than convincing them yet again why it's not a priority. I've been facilitating refinement meetings every week for my teams for the past two years. &lt;a href="https://butyoudontlooksick.com/articles/written-by-christine/the-spoon-theory/"&gt;I only have a finite amount of energy&lt;/a&gt; that is not always worth expending by refuting the case for a small edge case week after week. &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Shoutout to my logic professor Dan Cohen at Colby College, who had us memorize and distinguish logical fallacies as part of his brilliant Logic and Argumentation course, and pointing out that an ease and comfort with truth tables would translate well to a computer science course. Special thanks to Joep Schuurkes for his philosophical and technological opinions on this piece.&lt;/p&gt;</description><category>critical-thinking</category><category>logic</category><category>naming</category><category>testing</category><guid>https://elizabethzagroba.com/posts/2021/recently_encountered_logical_falacies/</guid><pubDate>Tue, 30 Mar 2021 22:00:00 GMT</pubDate></item></channel></rss>